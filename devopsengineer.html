<!doctype html>
<html lang="en">
<head>
<title>devopsengineer</title>
<meta name="generator" content="Etherpad">
<meta name="author" content="Etherpad">
<meta name="changedby" content="Etherpad">
<meta charset="utf-8">
<style>
ol {
  counter-reset: item;
}

ol > li {
  counter-increment: item;
}

ol ol > li {
  display: block;
}

ol > li {
  display: block;
}

ol > li:before {
  content: counters(item, ".") ". ";
}

ol ol > li:before {
  content: counters(item, ".") ". ";
  margin-left: -20px;
}

ul.indent {
  list-style-type: none;
}


</style>
</head>
<body>
username: student<br>password: student<br><br>username: root<br>password: redhat<br><br><a href="https&#x3a;&#x2F;&#x2F;discuss&#x2e;kubernetes&#x2e;io&#x2F;t&#x2F;backup&#x2d;and&#x2d;restore&#x2d;etcd&#x2d;database&#x2F;12889" rel="noreferrer noopener">https:&#x2F;&#x2F;discuss.kubernetes.io&#x2F;t&#x2F;backup-and-restore-etcd-database&#x2F;12889</a><br><a href="https&#x3a;&#x2F;&#x2F;artifacthub&#x2e;io&#x2F;" rel="noreferrer noopener">https:&#x2F;&#x2F;artifacthub.io&#x2F;</a><br><a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;cri&#x2d;o&#x2F;cri&#x2d;o&#x2F;blob&#x2F;main&#x2F;docs&#x2F;crio&#x2e;conf&#x2e;5&#x2e;md" rel="noreferrer noopener">https:&#x2F;&#x2F;github.com&#x2F;cri-o&#x2F;cri-o&#x2F;blob&#x2F;main&#x2F;docs&#x2F;crio.conf.5.md</a><br><a href="https&#x3a;&#x2F;&#x2F;man7&#x2e;org&#x2F;linux&#x2F;man&#x2d;pages&#x2F;man7&#x2F;capabilities&#x2e;7&#x2e;html" rel="noreferrer noopener">https:&#x2F;&#x2F;man7.org&#x2F;linux&#x2F;man-pages&#x2F;man7&#x2F;capabilities.7.html</a><br><a href="https&#x3a;&#x2F;&#x2F;grafana&#x2e;com&#x2F;grafana&#x2F;dashboards&#x2F;6417&#x2d;kubernetes&#x2d;cluster&#x2d;prometheus&#x2F;" rel="noreferrer noopener">https:&#x2F;&#x2F;grafana.com&#x2F;grafana&#x2F;dashboards&#x2F;6417-kubernetes-cluster-prometheus&#x2F;</a><br><a href="https&#x3a;&#x2F;&#x2F;dev&#x2e;to&#x2F;jmarhee&#x2F;how&#x2d;to&#x2d;delete&#x2d;a&#x2d;kubernetes&#x2d;namespace&#x2d;stuck&#x2d;at&#x2d;terminating&#x2d;status&#x2d;53o5" rel="noreferrer noopener">https:&#x2F;&#x2F;dev.to&#x2F;jmarhee&#x2F;how-to-delete-a-kubernetes-namespace-stuck-at-terminating-status-53o5</a><br><a href="https&#x3a;&#x2F;&#x2F;kubernetes&#x2e;io&#x2F;docs&#x2F;concepts&#x2F;services&#x2d;networking&#x2F;dns&#x2d;pod&#x2d;service&#x2F;" rel="noreferrer noopener">https:&#x2F;&#x2F;kubernetes.io&#x2F;docs&#x2F;concepts&#x2F;services-networking&#x2F;dns-pod-service&#x2F;</a><br><a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;kubernetes&#x2F;ingress&#x2d;nginx&#x2F;blob&#x2F;main&#x2F;deploy&#x2F;static&#x2F;provider&#x2F;baremetal&#x2F;deploy&#x2e;yaml" rel="noreferrer noopener">https:&#x2F;&#x2F;github.com&#x2F;kubernetes&#x2F;ingress-nginx&#x2F;blob&#x2F;main&#x2F;deploy&#x2F;static&#x2F;provider&#x2F;baremetal&#x2F;deploy.yaml</a><br><a href="https&#x3a;&#x2F;&#x2F;helm&#x2e;sh&#x2F;docs&#x2F;intro&#x2F;install&#x2F;" rel="noreferrer noopener">https:&#x2F;&#x2F;helm.sh&#x2F;docs&#x2F;intro&#x2F;install&#x2F;</a><br><a href="https&#x3a;&#x2F;&#x2F;artifacthub&#x2e;io&#x2F;packages&#x2F;helm&#x2F;k8s&#x2d;dashboard&#x2F;kubernetes&#x2d;dashboard" rel="noreferrer noopener">https:&#x2F;&#x2F;artifacthub.io&#x2F;packages&#x2F;helm&#x2F;k8s-dashboard&#x2F;kubernetes-dashboard</a><br><br><strong><u>Day - 1</u></strong><br><br><br>[student@master ~]$ pwd<br>&#x2F;home&#x2F;student.<br>[student@master ~]$ cd Desktop&#x2F;<br>[student@master Desktop]$ ls<br>[student@master Desktop]$ cd<br>[student@master ~]$ ls<br>Desktop&nbsp; Documents&nbsp; Downloads&nbsp; Music&nbsp; Pictures&nbsp; Public&nbsp; Templates&nbsp; Videos<br><br>[student@master ~]$ ls &#x2F;<br>bin&nbsp; boot&nbsp; dev&nbsp; etc&nbsp; home&nbsp; lib&nbsp; lib64&nbsp; media&nbsp; mnt&nbsp; opt&nbsp; proc&nbsp; root&nbsp; run&nbsp; sbin&nbsp; srv&nbsp; sys&nbsp; tmp&nbsp; usr&nbsp; var<br><br>e[student@master ~]$ lsblk<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; MAJ:MIN RM&nbsp; SIZE RO TYPE MOUNTPOINT<br>sda&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8:0&nbsp;&nbsp;&nbsp; 0&nbsp; 100G&nbsp; 0 disk&nbsp;<br>&#9500;&#9472;sda1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8:1&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp; 1G&nbsp; 0 part &#x2F;boot<br>&#9492;&#9472;sda2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8:2&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp; 99G&nbsp; 0 part&nbsp;<br>&nbsp; &#9500;&#9472;centos-root 253:0&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp; 50G&nbsp; 0 lvm&nbsp; &#x2F;<br>&nbsp; &#9500;&#9472;centos-swap 253:1&nbsp;&nbsp;&nbsp; 0&nbsp; 7.9G&nbsp; 0 lvm&nbsp;&nbsp;<br>&nbsp; &#9492;&#9472;centos-home 253:2&nbsp;&nbsp;&nbsp; 0 41.1G&nbsp; 0 lvm&nbsp; &#x2F;home<br>sr0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 11:0&nbsp;&nbsp;&nbsp; 1 1024M&nbsp; 0 rom&nbsp;&nbsp;<br><br>&#x2F; - root file system<br>&#x2F;usr - installed software (&#x2F;usr&#x2F;bin)<br>&#x2F;etc - configuration files<br>&#x2F;var - log files&nbsp;<br>&#x2F;run - files since last boot<br>&#x2F;tmp - temporary files<br>&#x2F;home - home directory for regular user<br>&#x2F;root - home directory for root user<br>&#x2F;boot - files to boot your OS<br>&#x2F;dev - device files (sda)<br><br>[student@master ~]$ man 7 hier<br><br>[student@master ~]$ touch file1.txt<br>[student@master ~]$ ls<br>Desktop&nbsp; Documents&nbsp; Downloads&nbsp; file1.txt&nbsp; Music&nbsp; Pictures&nbsp; Public&nbsp; Templates&nbsp; Videos<br>[student@master ~]$ touch file2.txt file3.txt<br>[student@master ~]$ ls<br>Desktop&nbsp; Documents&nbsp; Downloads&nbsp; file1.txt&nbsp; file2.txt&nbsp; file3.txt&nbsp; Music&nbsp; Pictures&nbsp; Public&nbsp; Templates&nbsp; Videos<br><br>[student@master ~]$ mkdir dir1 dir22<br>[student@master ~]$ ls<br>Desktop&nbsp; dir1&nbsp; dir22&nbsp; Documents&nbsp; Downloads&nbsp; file1.txt&nbsp; file2.txt&nbsp; file3.txt&nbsp; Music&nbsp; Pictures&nbsp; Public&nbsp; Templates&nbsp; Videos<br><br>[student@master ~]$ man mkdir<br><br>[student@master ~]$ cp file1.txt file2.txt file3.txt dir1&#x2F;<br>[student@master ~]$ ls dir1<br>file1.txt&nbsp; file2.txt&nbsp; file3.txt<br><br>[student@master ~]$ rm file1.txt file2.txt file3.txt&nbsp;<br>[student@master ~]$ ls<br>Desktop&nbsp; dir1&nbsp; dir22&nbsp; Documents&nbsp; Downloads&nbsp; Music&nbsp; Pictures&nbsp; Public&nbsp; Templates&nbsp; Videos<br><br>[student@master ~]$ cd dir1&#x2F;<br>[student@master dir1]$ ls<br>file1.txt&nbsp; file2.txt&nbsp; file3.txt<br>[student@master dir1]$ mv file1.txt file100.txt<br>[student@master dir1]$ ls<br>file100.txt&nbsp; file2.txt&nbsp; file3.txt<br><br>[student@master dir1]$ cd&nbsp;<br>[student@master ~]$ ls<br>Desktop&nbsp; dir1&nbsp; dir22&nbsp; Documents&nbsp; Downloads&nbsp; Music&nbsp; Pictures&nbsp; Public&nbsp; Templates&nbsp; Videos<br>[student@master ~]$ rmdir dir22<br>[student@master ~]$ ls<br>Desktop&nbsp; dir1&nbsp; Documents&nbsp; Downloads&nbsp; Music&nbsp; Pictures&nbsp; Public&nbsp; Templates&nbsp; Videos<br>[student@master ~]$ rmdir dir1<br>rmdir: failed to remove &#8216;dir1&#8217;: Directory not empty<br>[student@master ~]$ rm -r dir1&#x2F;<br>[student@master ~]$ ls<br>Desktop&nbsp; Documents&nbsp; Downloads&nbsp; Music&nbsp; Pictures&nbsp; Public&nbsp; Templates&nbsp; Videos<br><br>[student@master ~]$ touch file1.txt<br>[student@master ~]$ vim file1.txt&nbsp;<br><br>[student@master ~]$ vimtutor<br><br>[student@master ~]$ id<br>uid=1000(student) gid=1000(student) groups=1000(student) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023<br><br>[student@master ~]$ su -<br>Password:&nbsp;<br>Last login: Fri Oct 28 08:52:30 IST 2022 on pts&#x2F;0<br>Last failed login: Wed Nov&nbsp; 2 22:38:32 IST 2022 on pts&#x2F;1<br>There was 1 failed login attempt since the last successful login.<br>[root@master ~]# id<br>uid=0(root) gid=0(root) groups=0(root) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023<br><br>[root@master ~]# useradd user01<br>[root@master ~]# id user01<br>uid=1001(user01) gid=1001(user01) groups=1001(user01)<br><br>[student@master ~]$ cat &#x2F;etc&#x2F;passwd<br><br>[root@master ~]# passwd user01<br>Changing password for user user01.<br>New password:&nbsp;<br>BAD PASSWORD: The password is shorter than 8 characters<br>Retype new password:&nbsp;<br>passwd: all authentication tokens updated successfully.<br><br>[student@master ~]$ su - user01<br>Password:&nbsp;<br>[user01@master ~]$ exit<br>logout<br>[student@master ~]$&nbsp;<br><br>[root@master ~]# usermod -u 2000 user01<br>[root@master ~]# id user01<br>uid=2000(user01) gid=1001(user01) groups=1001(user01)<br>[root@master ~]#&nbsp;<br>[root@master ~]# userdel -r user01<br>[root@master ~]#&nbsp;<br>[root@master ~]# ls &#x2F;home<br>student<br><br><strong><u>Day - 2</u></strong><br><br>[student@master ~]$ ls -l file1.txt&nbsp;<br>-rw-rw-r--. 1 student student 76 Nov&nbsp; 2 22:02 file1.txt<br><br>[student@master ~]$ chmod o-r file1.txt<br>[student@master ~]$ ls -l file1.txt&nbsp;<br>-rw-rw----. 1 student student 76 Nov&nbsp; 2 22:02 file1.txt<br><br><br>[student@master ~]$ chmod o+r file1.txt&nbsp;<br>[student@master ~]$ ls -l file1.txt&nbsp;<br>-rw-rw-r--. 1 student student 76 Nov&nbsp; 2 22:02 file1.txt<br><br>[student@master ~]$ chmod o-rwx testdir&#x2F;<br>[student@master ~]$ ls -l<br>total 4<br>drwxr-xr-x. 3 student student 20 Nov&nbsp; 2 20:35 Desktop<br>drwxr-xr-x. 2 student student&nbsp; 6 Nov 27&nbsp; 2020 Documents<br>drwxr-xr-x. 2 student student&nbsp; 6 Nov 27&nbsp; 2020 Downloads<br>-rw-rw-r--. 1 student student 76 Nov&nbsp; 2 22:02 file1.txt<br>drwxr-xr-x. 2 student student&nbsp; 6 Nov 27&nbsp; 2020 Music<br>drwxr-xr-x. 2 student student&nbsp; 6 Nov 27&nbsp; 2020 Pictures<br>drwxr-xr-x. 2 student student&nbsp; 6 Nov 27&nbsp; 2020 Public<br>drwxr-xr-x. 2 student student&nbsp; 6 Nov 27&nbsp; 2020 Templates<br>drwxrwx---. 2 student student&nbsp; 6 Nov&nbsp; 3 20:33 testdir<br>drwxr-xr-x. 2 student student&nbsp; 6 Nov 27&nbsp; 2020 Videos<br><br>[student@master ~]$ systemctl list-units --type=service<br><br>[student@master ~]$ systemctl status NetworkManager.service&nbsp;<br><br>[root@master ~]# systemctl start NetworkManager.service<br>[root@master ~]# systemctl stop NetworkManager.service<br>[root@master ~]# systemctl enable NetworkManager.service<br><br>[root@master ~]# yum repolist<br>Loaded plugins: fastestmirror, langpacks<br>Loading mirror speeds from cached hostfile<br>&nbsp;* base: mirrors.nxtgen.com<br>&nbsp;* epel: mirror2.totbb.net<br>&nbsp;* extras: mirrors.nxtgen.com<br>&nbsp;* updates: mirrors.nxtgen.com<br>repo id&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; repo name&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; status<br>!base&#x2F;7&#x2F;x86_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CentOS-7 - Base&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10,072<br>!devel_kubic_libcontainers_stable&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Stable Releases of Upstream github.com&#x2F;containers packages (CentOS_7)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 19<br>!devel_kubic_libcontainers_stable_cri-o_1.21&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; devel:kubic:libcontainers:stable:cri-o:1.21 (CentOS_7)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4<br>!docker-ce-stable&#x2F;7&#x2F;x86_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Docker CE Stable - x86_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 183<br>!epel&#x2F;x86_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Extra Packages for Enterprise Linux 7 - x86_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 13,734<br>!extras&#x2F;7&#x2F;x86_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CentOS-7 - Extras&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 515<br>!hashicorp&#x2F;7&#x2F;x86_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Hashicorp Stable - x86_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 939<br>!kubernetes&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kubernetes&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 879<br>!updates&#x2F;7&#x2F;x86_64&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CentOS-7 - Updates&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4,346<br>repolist: 30,691<br><br>[root@master ~]# yum search terraform<br><br>[root@master ~]# yum search git<br><br>[root@master ~]# yum search ansible<br><br>[root@master ~]# yum info git<br><br>[root@master ~]# yum install httpd<br><br>[root@master ~]# systemctl enable httpd<br>Created symlink from &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;multi-user.target.wants&#x2F;httpd.service to &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;system&#x2F;httpd.service.<br>[root@master ~]# systemctl start httpd<br><br>[root@master ~]# yum remove httpd<br><br>[root@master ~]# yum list git<br><br><br><strong><u>Day - 3</u></strong><br><br>[root@master ~]# yum install git<br><br>[student@master ~]$ mkdir projectfiles<br>[student@master ~]$ cd projectfiles&#x2F;<br>[student@master projectfiles]$ git config --global user.name &quot;docdoom12345&quot;<br>[student@master projectfiles]$ git config --global user.email &quot;docdoom12345@outlook.com&quot;<br><br>[student@master projectfiles]$ git init<br>Initialized empty Git repository in &#x2F;home&#x2F;student&#x2F;projectfiles&#x2F;.git&#x2F;<br><br>[student@master projectfiles]$ touch file1.txt<br>[student@master projectfiles]$ vim file1.txt<br>[student@master projectfiles]$ touch file2.txt<br>[student@master projectfiles]$ vim file2.txt<br>[student@master projectfiles]$ cat file1.txt file2.txt&nbsp;<br>this is file1<br>this is file2<br><br>[student@master projectfiles]$ git status<br># On branch master<br>#<br># Initial commit<br>#<br># Untracked files:<br>#&nbsp;&nbsp; (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed)<br>#<br>#&nbsp;&nbsp;&nbsp; file1.txt<br>#&nbsp;&nbsp;&nbsp; file2.txt<br>nothing added to commit but untracked files present (use &quot;git add&quot; to track)<br><br>[student@master projectfiles]$ git add file1.txt file2.txt<br>[student@master projectfiles]$ git status<br># On branch master<br>#<br># Initial commit<br>#<br># Changes to be committed:<br>#&nbsp;&nbsp; (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage)<br>#<br>#&nbsp;&nbsp;&nbsp; new file:&nbsp;&nbsp; file1.txt<br>#&nbsp;&nbsp;&nbsp; new file:&nbsp;&nbsp; file2.txt<br><br>[student@master projectfiles]$ git commit -m &quot;added file1.txt and file2.txt&quot;<br>[master (root-commit) b6b6bbb] added file1.txt and file2.txt<br>&nbsp;2 files changed, 2 insertions(+)<br>&nbsp;create mode 100644 file1.txt<br>&nbsp;create mode 100644 file2.txt<br>[student@master projectfiles]$ git status<br># On branch master<br>nothing to commit, working directory clean<br><br>[student@master projectfiles]$ git add file1.txt<br>[student@master projectfiles]$ git commit -m &quot;updated file1.txt&quot;<br>[master 1cb1c39] updated file1.txt<br>&nbsp;1 file changed, 1 insertion(+)<br><br>[student@master projectfiles]$ git log<br>commit 1cb1c39e106554f0fced4c0f53a5bf8f9b33c2dc<br>Author: docdoom12345 &lt;docdoom12345@outlook.com&gt;<br>Date:&nbsp;&nbsp; Fri Nov 4 20:43:55 2022 +0530<br><br>&nbsp;&nbsp;&nbsp; updated file1.txt<br><br>commit b6b6bbbc26f8bc0799be7678638c7c4b8e956d38<br>Author: docdoom12345 &lt;docdoom12345@outlook.com&gt;<br>Date:&nbsp;&nbsp; Fri Nov 4 20:36:18 2022 +0530<br><br>&nbsp;&nbsp;&nbsp; added file1.txt and file2.txt<br><br>[student@master projectfiles]$ git show<br><br>[student@master projectfiles]$ git branch version1.0<br>[student@master projectfiles]$ git branch --all<br>* master<br>&nbsp; version1.0<br><br>[student@master projectfiles]$ git checkout version1.0&nbsp;<br>Switched to branch &#x27;version1.0&#x27;<br>[student@master projectfiles]$ git branch<br>&nbsp; master<br>* version1.0<br><br>[student@master projectfiles]$ touch file3.txt<br>[student@master projectfiles]$ vim file3.txt&nbsp;<br>[student@master projectfiles]$ cat file3.txt&nbsp;<br>this is a new file<br><br>[student@master projectfiles]$ git add file3.txt<br>[student@master projectfiles]$ git commit -m &quot;updated file3.txt&quot;<br>[version1.0 8f4f320] updated file3.txt<br>&nbsp;1 file changed, 1 insertion(+)<br>&nbsp;create mode 100644 file3.txt<br><br>[student@master projectfiles]$ git remote -v<br><br>[student@master projectfiles]$ git push origin version1.0&nbsp;<br>Username for &#x27;<a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com" rel="noreferrer noopener">https:&#x2F;&#x2F;github.com</a>&#x27;: docdoom12345<br>Password for &#x27;<a href="https&#x3a;&#x2F;&#x2F;docdoom12345&#x40;github&#x2e;com" rel="noreferrer noopener">https:&#x2F;&#x2F;docdoom12345@github.com</a>&#x27;:&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;<br>[student@master projectfiles]$ git push origin master<br>Username for &#x27;<a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com" rel="noreferrer noopener">https:&#x2F;&#x2F;github.com</a>&#x27;: docdoom12345<br>Password for &#x27;<a href="https&#x3a;&#x2F;&#x2F;docdoom12345&#x40;github&#x2e;com" rel="noreferrer noopener">https:&#x2F;&#x2F;docdoom12345@github.com</a>&#x27;:&nbsp;<br><br>[student@master projectfiles]$ git checkout master<br>Switched to branch &#x27;master&#x27;<br>[student@master projectfiles]$ git branch<br>* master<br>&nbsp; version1.0<br>[student@master projectfiles]$ git merge version1.0&nbsp;<br>Updating 1cb1c39..8f4f320<br>Fast-forward<br>&nbsp;file3.txt | 1 +<br>&nbsp;1 file changed, 1 insertion(+)<br>&nbsp;create mode 100644 file3.txt<br>[student@master projectfiles]$ git log --oneline<br>8f4f320 updated file3.txt<br>1cb1c39 updated file1.txt<br>b6b6bbb added file1.txt and file2.txt<br><br>[student@master projectfiles]$ git tag -a v1.0 -m &quot;my version 1.0&quot;<br>[student@master projectfiles]$ git tag<br>v1.0<br>[student@master projectfiles]$ git show v1.0<br><br>[student@master projectfiles]$ git push origin v1.0&nbsp;<br>Username for &#x27;<a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com" rel="noreferrer noopener">https:&#x2F;&#x2F;github.com</a>&#x27;: docdoom12345<br>Password for &#x27;<a href="https&#x3a;&#x2F;&#x2F;docdoom12345&#x40;github&#x2e;com" rel="noreferrer noopener">https:&#x2F;&#x2F;docdoom12345@github.com</a>&#x27;:&nbsp;<br>Counting objects: 1, done.<br>Writing objects: 100% (1&#x2F;1), 161 bytes | 0 bytes&#x2F;s, done.<br>Total 1 (delta 0), reused 0 (delta 0)<br>To <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;docdoom12345&#x2F;githubrepo&#x2e;git" rel="noreferrer noopener">https:&#x2F;&#x2F;github.com&#x2F;docdoom12345&#x2F;githubrepo.git</a><br>&nbsp;* [new tag]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; v1.0 -&gt; v1.0<br>-------------------------------------------------------------------------------------------------------------------------------<br><strong>PRACTICE QUESTION</strong><br>1. Create a new branch samplebranch<br>git branch samplebranch<br><br>2. add 4 files fire100.txt fire200.txt fire300.txt fire400.txt<br>touch fire100.txt fire200.txt fire300.txt fire400.txt<br>git add fire100.txt fire200.txt fire300.txt fire400.txt<br><br>3. commit the changes<br>git commit -m &quot;added 4 files&quot;<br><br>4. upload these changes to github<br>git push origin samplebranch<br><br>5. merge the branch with master branch<br>git switch master<br>git merge samplebranch<br>-------------------------------------------------------------------------------------------------------------------------------<br><strong><u>Day - 4</u></strong><br><strong>Install docker</strong><br>yum install -y docker-ce<br>systemctl enable docker --now<br><br><br>Create docker hub account - <a href="https&#x3a;&#x2F;&#x2F;hub&#x2e;docker&#x2e;com&#x2F;" rel="noreferrer noopener">https:&#x2F;&#x2F;hub.docker.com&#x2F;</a><br><br><strong>Download image</strong><br>docker pull ubuntu:22.04<br>docker pull nginx<br>docker pull quay.io&#x2F;bedrock&#x2F;ubuntu<br><br><strong>Creating container</strong><br>docker run -itd --name ubuntu-container ubuntu:22.04<br><br><strong>start and stop container</strong><br>[root@master ~]# docker stop ubuntu-container&nbsp;<br>ubuntu-container<br>[root@master ~]# docker ps<br>CONTAINER ID&nbsp;&nbsp; IMAGE&nbsp;&nbsp;&nbsp;&nbsp; COMMAND&nbsp;&nbsp; CREATED&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; PORTS&nbsp;&nbsp;&nbsp;&nbsp; NAMES<br>[root@master ~]# docker start ubuntu-container&nbsp;<br>ubuntu-container<br>[root@master ~]# docker ps<br>CONTAINER ID&nbsp;&nbsp; IMAGE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; COMMAND&nbsp;&nbsp; CREATED&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; PORTS&nbsp;&nbsp;&nbsp;&nbsp; NAMES<br>9732fb2472cd&nbsp;&nbsp; ubuntu:22.04&nbsp;&nbsp; &quot;bash&quot;&nbsp;&nbsp;&nbsp; 9 minutes ago&nbsp;&nbsp; Up 2 seconds&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ubuntu-container<br><br><strong>Note: </strong>Use docker ps -a&nbsp;&nbsp; to see all containers<br><strong>inspect container</strong><br>[root@master ~]# docker inspect ubuntu-container&nbsp;<br><strong>interact with container</strong><br>[root@master ~]# docker exec -it ubuntu-container bash<br><br><strong>push an image to docker hub</strong><br>[root@master ~]# docker tag ubuntu:22.04 docdoom12345&#x2F;dockerrepo:22.04<br>[root@master ~]# docker push docdoom12345&#x2F;dockerrepo:22.04<br><br><strong>check history of image</strong><br>[root@master ~]# docker history ubuntu:22.04<br>----------------------------<br><strong>DAY 5&nbsp;</strong><br><strong>FROM -&gt;to create image template for existing container</strong><br><strong>RUN -&gt; commands to be executed</strong><br><strong>ADD -&gt; transfer file to image during creation</strong><br><strong>COPY -&gt; transfer from local machine to image</strong><br><strong>MAINTAINER -&gt; creator</strong><br><strong>ENTRYPOINT -&gt; what should get executed when container is created?</strong><br><strong>CMD -&gt; provide optional command to interact with container</strong><br><strong>EXPOSE -&gt; open port numbers</strong><br><strong>ENV -&gt; environment variables</strong><br><strong>creating an image</strong><br><br>[root@master ~]# echo &quot;this is a web page&quot; &gt; index.html<br>[root@master ~]# echo &quot;service apache2 restart&quot; &gt; service.sh<br>[root@master ~]# chmod +x service.sh<br><br>FROM ubuntu:22.04<br>RUN apt-get update -y<br>RUN apt-get install apache2 -y<br>COPY index.html &#x2F;var&#x2F;www&#x2F;html&#x2F;index.html<br>COPY service.sh &#x2F;root&#x2F;service.sh<br>EXPOSE 80<br>ENTRYPOINT &#x2F;root&#x2F;service.sh ; &#x2F;bin&#x2F;bash<br><br>[root@master ~]# cat Dockerfile&nbsp;<br>[root@master ~]# docker build . -t ubuntu-web:v1<br>[root@master ~]# docker inspect ubuntu-web<br><br><strong>private registry</strong><br>[root@master ~]# docker pull registry<br><br>[root@master ~]# docker run -itd -p 5000:5000 --name=private registry:latest&nbsp;<br><br>[root@master ~]# docker tag ubuntu-web:v1 localhost:5000&#x2F;ubuntu:web-v1<br>[root@master ~]# docker push localhost:5000&#x2F;ubuntu:web-v1<br><br>-------<br><strong>STORAGE</strong><br><strong>bindmount</strong><br><br>[root@master ~]# mkdir binddir<br>[root@master ~]# docker run -itd -v &#x2F;root&#x2F;binddir:&#x2F;storage --name bind-container ubuntu:22.04<br>8cd120163e8fddc4c352e6dfeae2e1884e57775526dbe7159b6fefdd297bc016<br>[root@master ~]# docker exec -it bind-container bash<br>root@8cd120163e8f:&#x2F;# ls&nbsp;<br>bin&nbsp; boot&nbsp; dev&nbsp; etc&nbsp; home&nbsp; lib&nbsp; lib32&nbsp; lib64&nbsp; libx32&nbsp; media&nbsp; mnt&nbsp; opt&nbsp; proc&nbsp; root&nbsp; run&nbsp; sbin&nbsp; srv&nbsp; storage&nbsp; sys&nbsp; tmp&nbsp; usr&nbsp; var<br>root@8cd120163e8f:&#x2F;# touch storage&#x2F;testing.txt<br>root@8cd120163e8f:&#x2F;# exit<br>exit<br>[root@master ~]# ls binddir&#x2F;<br>testing.txt<br><br><strong>volume</strong><br>[root@master ~]# docker volume create vol1<br>vol1<br>[root@master ~]# docker volume ls<br>DRIVER&nbsp;&nbsp;&nbsp; VOLUME NAME<br>local&nbsp;&nbsp;&nbsp;&nbsp; 49b67d21e1ca909aac8bf37f27fb852076d5342871cf932837c2cf9b6abbab35<br>local&nbsp;&nbsp;&nbsp;&nbsp; vol1<br>[root@master ~]# docker run -itd -v vol1:&#x2F;storage --name vol-container ubuntu:22.04<br>9264144f82f37255bc9ee4f6c1b099165123fce93dfae3ca5339ccd50fb2941f<br><br>[root@master ~]# docker exec -it vol-container bash<br>root@9264144f82f3:&#x2F;# touch storage&#x2F;testing.txt<br>root@9264144f82f3:&#x2F;# exit<br>exit<br>[root@master ~]# ls &#x2F;var&#x2F;lib&#x2F;docker&#x2F;volumes&#x2F;vol1&#x2F;_data&#x2F;<br>testing.txt<br><br>[root@master ~]# docker volume inspect vol1&nbsp;<br>......<br><strong>Networking</strong><br><strong>create bridge</strong><br>[root@master ~]# docker network create testbridge --driver=bridge --subnet=192.168.50.0&#x2F;24<br>fb9a69b3bb0d15af296b8589fcc42106b22a517eb0137631184e6557a2711cc3<br><br><strong>create container</strong><br>[root@master ~]# docker run -itd --network testbridge --name bridge-container ubuntu:22.04&nbsp;<br>d51c5dc537ae5b81633bffb24962736dacb9ef70e9cde72236a74bac58c1e77a<br><strong>connect containers</strong><br>[root@master ~]# docker network connect testbridge ubuntu-container&nbsp;<br><br>docker exec -it ubuntu-container bash<br>apt-get update -y &amp;&amp; apt-get install net-tools -y &amp;&amp; apt-get install iputils-ping -y<br>ping -c 5 &lt;ip&gt;<br><strong>container with host network`</strong><br>[root@master ~]# docker run -itd --network host --name host-container ubuntu:22.04<br>6d0bebc760843b402a44c09dc3f826679f3e35c761a27decdae092020984bff6<br><br><strong>container with no network</strong><br>[root@master ~]# docker run -itd --network none --name none-container ubuntu:22.04<br>52ff29343d2120d2f219b232c1263421486a1d45673e1b343ba3d3cbe17db373<br>-------------------------<br><strong>EXERCISE</strong><br><br>Create 2 containers dev-container and prod-container as follows<br><ol start="1" class="number"><li>dev-container should be in network 172.24.0.0&#x2F;24</li><li>prod-container should be in network 172.25.0.0&#x2F;24</li><li>dev-container should host a static web page when started</li><li>dev-container and prod-container should connect to each other</ol>docker network connect dev-bridge prod-container<br>-------------------------<br><strong>DAY 6</strong><br><strong>Kubernetes setup</strong><br><strong>Step 1</strong>: On master, configure &#x2F;etc&#x2F;hosts as per IP of your machines<br>172.25.231.97 master<br>172.25.230.24 worker1<br>172.25.232.187 worker2<br><br>Verify using ping worker1, ping worker2.<br><br><strong>Step 2:</strong>- copy hosts file to worker machines (password is redhat)<br>scp -r &#x2F;etc&#x2F;hosts worker1:&#x2F;etc<br>scp -r &#x2F;etc&#x2F;hosts worker2:&#x2F;etc<br><br><strong>Step 3</strong>: ssh into worker1, worker2 (password is redhat)<br>on master, open 2 terminal tabs and run<br>ssh root@worker1<br>ssh root@worker2<br><br><strong>Step 4</strong>: turn of swap on all machines<br>swapoff -a<br>=unixso<br><strong>Step 5</strong>: install packages on all mach<br>yum install crio kubelet kubectl kubeadm -y<br><br><strong>Step 6: start crio and kubelet on all machines</strong><br>systemctl enable crio kubelet --now<br><br><strong>step 7:</strong> setup master node<br>kubeadm init --pod-network-cidr=10.244.0.0&#x2F;16 --cri-socket=unix:&#x2F;&#x2F;&#x2F;var&#x2F;run&#x2F;crio&#x2F;crio.sock<br><br><strong>step 8</strong>: start cluster on master node<br>run 3 commands on master node as per your output<br><br><strong>step 9</strong>: add worker node to cluster<br>run 1 command on worker node as per your output<br><br><strong>step 10: verify cluster in master node</strong><br>[root@master ~]# kubectl get nodes<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; STATUS&nbsp;&nbsp; ROLES&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AGE&nbsp;&nbsp; VERSION<br>master&nbsp;&nbsp;&nbsp; Ready&nbsp;&nbsp;&nbsp; control-plane&nbsp;&nbsp; 12m&nbsp;&nbsp; v1.25.4<br>worker1&nbsp;&nbsp; Ready&nbsp;&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 83s&nbsp;&nbsp; v1.25.4<br>worker2&nbsp;&nbsp; Ready&nbsp;&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 80s&nbsp;&nbsp; v1.25.4<br><br><strong>step 11:</strong> download calico on master<br>wget <a href="http&#x3a;&#x2F;&#x2F;raw&#x2e;githubusercontent&#x2e;com&#x2F;projectcalico&#x2F;calico&#x2F;v3&#x2e;24&#x2e;0&#x2F;manifests&#x2F;calico&#x2e;yaml" rel="noreferrer noopener">http:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;projectcalico&#x2F;calico&#x2F;v3.24.0&#x2F;manifests&#x2F;calico.yaml</a><br><br><strong>step 12</strong>: change image registry on master<br>open calico.yaml and type Esc :%s&#x2F;docker.io&#x2F;quay.io&#x2F;g and hit enter. Save the file<br>kubectl apply -f calico.yaml<br>----------------------------------<br><strong>Day 7</strong><br>vim settings update<br><br>vim ~&#x2F;.vimrc<br>set cursorline cursorcolumn<br><strong>pod creation</strong><br><strong>firstpod.yaml</strong><br>apiVersion: v1i<br>kind: Pod<br>metadata:<br>&nbsp;name: test-pod<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: qc<br>&nbsp;&nbsp;&nbsp;<br>[root@master scripts]# kubectl apply -f firstpod.yaml&nbsp;<br>pod&#x2F;test-pod created<br>-----<br><strong>test.yaml</strong><br>apiVersion: v1<br>kind: Pod<br>metadata:&nbsp;&nbsp;<br>&nbsp;name: nginx-pod<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mywebapp<br>&nbsp;&nbsp; imagePullPolicy: IfNotPresent #Always,Never,IfNotPresent<br>--------<br><strong>commands</strong><br>kubectl apply -f file.yaml<br>kubectl get pods<br>kubectl delete -f file.yaml<br>kubectl delete pod&#x2F;podname<br>kubectl describe pod&#x2F;podname<br>-------<br><strong>podwithlabel.yaml</strong><br>apiVersion: v1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>kind: Pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>metadata:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;name: podwithlabel&nbsp;&nbsp;&nbsp;<br>&nbsp;labels:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp; dep: dev #key: value&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>spec:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;containers:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;- name: c1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mywebapp<br>&nbsp;&nbsp; imagePullPolicy: IfNotPresent #Always,Never,IfNotPresent<br>&nbsp;&nbsp;&nbsp;<br>[root@master scripts]# kubectl apply -f podwithlabel.yaml&nbsp;<br>pod&#x2F;podwithlabel created<br>[root@master scripts]# kubectl get pods --show-labels<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AGE&nbsp;&nbsp; LABELS<br>[root@master scripts]# kubectl get pods --show-labels<br>nginx-pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 13m&nbsp;&nbsp; &lt;none&gt;<br>podwithlabel&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 13s&nbsp;&nbsp; dep=dev<br>test-pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; CrashLoopBackOff&nbsp;&nbsp; 11 (2m48s ago)&nbsp;&nbsp; 34m&nbsp;&nbsp; &lt;none&gt;<br><br>label<br>[root@master scripts]# kubectl label --overwrite pods nginx-pod dep=test<br>pod&#x2F;nginx-pod labeled<br>[root@master scripts]# kubectl get pods --show-labels<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AGE&nbsp;&nbsp;&nbsp; LABELS<br>nginx-pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 22m&nbsp;&nbsp;&nbsp; dep=test<br>podwithlabel&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9m8s&nbsp;&nbsp; dep=dev<br>test-pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; CrashLoopBackOff&nbsp;&nbsp; 13 (86s ago)&nbsp;&nbsp; 43m&nbsp;&nbsp;&nbsp; &lt;none&gt;<br><br><strong>selector</strong><br><strong>equity</strong><br>[root@master scripts]# kubectl get pods --selector dep=dev<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE<br>podwithlabel&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 37m<br><strong>set based</strong><br>[root@master scripts]# kubectl get pods --selector &#x27;dep in (dev,test,prod)&#x27;<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE<br>nginx-pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 52m<br>podwithlabel&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 38m<br><br>-----<br><strong>Replication controller</strong><br>apiVersion: v1<br>kind: ReplicationController&nbsp;<br>metadata:<br>&nbsp;name: rc-example<br>spec:<br>&nbsp;replicas: 3 #number of pods needed<br>&nbsp;template: #pod specification<br>&nbsp; metadata:<br>&nbsp;&nbsp; name: web&nbsp; #pod name<br>&nbsp;&nbsp; labels:&nbsp;&nbsp;&nbsp; #pod label<br>&nbsp;&nbsp;&nbsp; dep: prod<br>&nbsp; spec:<br>&nbsp;&nbsp; containers: #container properties<br>&nbsp;&nbsp; - name: c1<br>&nbsp;&nbsp;&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mywebapp<br>&nbsp;&nbsp;&nbsp;&nbsp; imagePullPolicy: IfNotPresent<br><br>[root@master scripts]# kubectl get pods --selector dep=prod<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE<br>rc-example-4sq68&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 55s<br>rc-example-bj46q&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 55s<br>rc-example-bp6lf&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 55s<br>[root@master scripts]# kubectl delete pod&#x2F;rc-example-4sq68<br>pod &quot;rc-example-4sq68&quot; deleted<br>[root@master scripts]# kubectl get pods --selector dep=prod<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE<br>rc-example-bj46q&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2m9s<br>rc-example-bp6lf&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2m9s<br>rc-example-rxxtj&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 37s<br><br><strong>replicaset</strong><br>apiVersion: apps&#x2F;v1<br>kind: ReplicaSet<br>metadata:<br>&nbsp;name: rs-example<br>spec:<br>&nbsp;replicas: 3<br>&nbsp;selector: #condition for selector<br>&nbsp; matchExpressions:<br>&nbsp; - key: dep<br>&nbsp;&nbsp;&nbsp; operator: In<br>&nbsp;&nbsp;&nbsp; values:<br>&nbsp;&nbsp;&nbsp; - set1<br>&nbsp;&nbsp;&nbsp; - set2<br>&nbsp;template:<br>&nbsp; metadata:<br>&nbsp;&nbsp; name: web<br>&nbsp;&nbsp; labels:<br>&nbsp;&nbsp;&nbsp; dep: set1<br>&nbsp; spec:<br>&nbsp;&nbsp; containers:&nbsp;<br>&nbsp;&nbsp; - name: c1<br>&nbsp;&nbsp;&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mywebapp<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>[root@master scripts]# kubectl apply -f rs-example.yml&nbsp;<br>replicaset.apps&#x2F;rs-example created<br>[root@master scripts]# kubectl get pods --selector &#x27;dep=set1&#x27;<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE<br>rs-example-mxh7d&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16s<br>rs-example-pk6lf&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16s<br>rs-example-qtbj7&nbsp;&nbsp; 0&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; ContainerCreating&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16s<br>------------------------<br>[root@master scripts]# kubectl get pods --selector &#x27;dep in (set1,set2)&#x27; -o wide<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE&nbsp;&nbsp; IP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NODE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NOMINATED NODE&nbsp;&nbsp; READINESS GATES<br>rs-example-mxh7d&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 14m&nbsp;&nbsp; 10.244.235.133&nbsp;&nbsp; worker1&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;<br>rs-example-pk6lf&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 14m&nbsp;&nbsp; 10.244.189.73&nbsp;&nbsp;&nbsp; worker2&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;<br>rs-example-qtbj7&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 14m&nbsp;&nbsp; 10.244.235.134&nbsp;&nbsp; worker1&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;<br><br>-------<br><strong>service-pod.yaml</strong><br>apiVersion: apps&#x2F;v1<br>kind: ReplicaSet<br>metadata:<br>&nbsp;name: rs-webapp<br>spec:<br>&nbsp;replicas: 5<br>&nbsp;selector:<br>&nbsp; matchLabels:<br>&nbsp;&nbsp; app: webrs<br>&nbsp;template:<br>&nbsp; metadata:<br>&nbsp;&nbsp; labels:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp; app: webrs<br>&nbsp; spec:<br>&nbsp;&nbsp;&nbsp;<br>apiVersion: apps&#x2F;v1<br>kind: ReplicaSet<br>metadata:<br>&nbsp;name: rs-webapp<br>spec:<br>&nbsp;replicas: 5<br>&nbsp;selector:<br>&nbsp; matchLabels:<br>&nbsp;&nbsp; app: webrs<br>&nbsp;template:<br>&nbsp; metadata:<br>&nbsp;&nbsp;&nbsp; labels:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp; app: webrs<br>&nbsp; spec:<br><strong>clusterip.yaml</strong><br>apiVersion: v1<br>kind: Service<br>metadata:<br>&nbsp;name: clustersvc<br>spec:<br>&nbsp;type: ClusterIP<br>&nbsp;ports:<br>&nbsp;- targetPort: 80 #port of container<br>&nbsp;&nbsp; port: 5000 #port for accessing with clusterIP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;selector:<br>&nbsp; app: webrs<br><br>kubectl apply both files.<br>curl clusterip:port on worker node<br>-------------------------<br><strong>nodeport</strong><br>apiVersion: v1<br>kind: Service<br>metadata:<br>&nbsp;name: nodeportsvc<br>spec:<br>&nbsp;type: NodePort<br>&nbsp;ports:<br>&nbsp;- targetPort: 80 #main port of container<br>&nbsp;&nbsp; port: 8080 #alternate port of container -&gt; redirects to targetPort<br>&nbsp;&nbsp; nodePort: 30005 #port exposed on worker node&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;selector:<br>&nbsp; app: webrs<br><br>kubectl apply -f &lt;filename&gt;<br>curl worker1:nodeport on worker1<br><br>loadbalancer.yaml<br>apiVersion: v1<br>kind: Service<br>metadata:<br>&nbsp;name: lbsvc<br>spec:<br>&nbsp;type: LoadBalancer<br>&nbsp;ports:<br>&nbsp;- targetPort: 80 #pod port<br>&nbsp;&nbsp; port: 5000<br>&nbsp;selector:<br>&nbsp; app: webrs<br><br>[root@master scripts]# kubectl apply -f loadbalancer.yaml --dry-run<br>W1116 20:05:17.090071&nbsp;&nbsp;&nbsp; 8663 helpers.go:663] --dry-run is deprecated and can be replaced with --dry-run=client.<br>service&#x2F;lbsvc created (dry run)<br>[root@master scripts]# kubectl get svc<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; TYPE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CLUSTER-IP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; EXTERNAL-IP&nbsp;&nbsp; PORT(S)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AGE<br>clustersvc&nbsp;&nbsp;&nbsp; ClusterIP&nbsp;&nbsp; 10.96.2.65&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5000&#x2F;TCP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 21h<br>kubernetes&nbsp;&nbsp;&nbsp; ClusterIP&nbsp;&nbsp; 10.96.0.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 443&#x2F;TCP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 45h<br>nodeportsvc&nbsp;&nbsp; NodePort&nbsp;&nbsp;&nbsp; 10.106.193.41&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8080:30005&#x2F;TCP&nbsp;&nbsp; 20h<br>[root@master scripts]# kubectl apply -f loadbalancer.yaml<br>service&#x2F;lbsvc created<br>[root@master scripts]# et serkubectl gvice<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; TYPE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CLUSTER-IP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; EXTERNAL-IP&nbsp;&nbsp; PORT(S)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; AGE<br>clustersvc&nbsp;&nbsp;&nbsp; ClusterIP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10.96.2.65&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5000&#x2F;TCP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 21h<br>kubernetes&nbsp;&nbsp;&nbsp; ClusterIP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10.96.0.1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 443&#x2F;TCP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 45h<br>lbsvc&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; LoadBalancer&nbsp;&nbsp; 10.110.240.247&nbsp;&nbsp; &lt;pending&gt;&nbsp;&nbsp;&nbsp;&nbsp; 5000:32595&#x2F;TCP&nbsp;&nbsp; 11s<br>nodeportsvc&nbsp;&nbsp; NodePort&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10.106.193.41&nbsp;&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8080:30005&#x2F;TCP&nbsp;&nbsp; 20h<br>---------------------<br>schedule.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: worker1-pod<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mywebapp<br>&nbsp;nodeName: worker1<br><br>[root@master scripts]# kubectl apply -f schedule.yaml&nbsp;<br>pod&#x2F;worker1-pod created<br>[root@master scripts]# kubectl get pod&#x2F;worker1-pod -o wide<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE&nbsp;&nbsp; IP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NODE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NOMINATED NODE&nbsp;&nbsp; READINESS GATES<br>worker1-pod&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 13s&nbsp;&nbsp; 10.244.235.137&nbsp;&nbsp; worker1&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;<br><br>[root@master scripts]#kubectl taint nodes worker1 app=tester:NoSchedule<br>node&#x2F;worker1 tainted<br><br>nodetaint.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:&nbsp;<br>&nbsp;name: worker1-pod-taint<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mywebapp<br>&nbsp;tolerations:<br>&nbsp;- key: &quot;app&quot;<br>&nbsp;&nbsp; operator: &quot;Equal&quot;<br>&nbsp;&nbsp; value: &quot;tester&quot;<br>&nbsp;&nbsp; effect: &quot;NoSchedule&quot;&nbsp;<br><br>[root@master scripts]# kubectl apply -f nodetaint.yaml&nbsp;<br>pod&#x2F;worker1-pod-taint created<br>[root@master scripts]# kubectl get pod&#x2F;worker1-pod-taint -o wide<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE&nbsp;&nbsp; IP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NODE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NOMINATED NODE&nbsp;&nbsp; READINESS GATES<br>worker1-pod-taint&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16s&nbsp;&nbsp; 10.244.235.138&nbsp;&nbsp; worker1&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;<br>---------------------<br>---------<br><strong>node selector</strong><br>[root@master scripts]# kubectl taint nodes worker1 app-<br>node&#x2F;worker1 untainted<br>[root@master scripts]# kubectl label node worker2 size=medium<br>node&#x2F;worker2 labeled<br>[root@master scripts]# vim nodeselector.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: worker1-pod-selector<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mywebapp<br>&nbsp;nodeSelector:<br>&nbsp; size: medium<br>&nbsp;&nbsp;<br>[root@master scripts]# kubectl apply -f nodeselector.yaml&nbsp;<br>pod&#x2F;worker1-pod-selector created<br>[root@master scripts]# kubectl get pod&#x2F;worker1-pod-selector -o wide<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE&nbsp;&nbsp; IP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NODE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NOMINATED NODE&nbsp;&nbsp; READINESS GATES<br>worker1-pod-selector&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16s&nbsp;&nbsp; 10.244.189.77&nbsp;&nbsp; worker2&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;<br>-----------<br><strong>node affinity</strong><br>1.requiredDuringScheduling - label is must for node else pod won&#x27;t create here<br>2.preferredDuringScheduling - label is optional for node.<br>3.requiredDuringExecution - label is must for node else pod won&#x27;t run here (pod leaves the node if label not present)<br>4.ignoredDuringExecution - label is optional for node. ( pod stays in the node )<br>----<br>---------<br>node afiinity<br>[root@master scripts]# kubectl label node worker2 size=medium<br>node&#x2F;worker2 labeled<br>[root@master scripts]# vim nodeaffinity.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: nodeaffinity-pod<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mywebapp<br>&nbsp;affinity:<br>&nbsp; nodeAffinity:<br>&nbsp;&nbsp; requiredDuringSchedulingIgnoredDuringExecution:<br>&nbsp;&nbsp;&nbsp; nodeSelectorTerms:<br>&nbsp;&nbsp;&nbsp; - matchExpressions:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - key: &quot;size&quot;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; operator: &quot;In&quot;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; values:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; - &quot;medium&quot;<br><br>&nbsp;&nbsp;<br>[root@master scripts]# kubectl apply -f nodeaffinity.yaml&nbsp;<br>-----------<br>---------<br>deployment<br>deployment.yaml<br>apiVersion: apps&#x2F;v1<br>kind: Deployment<br>metadata:<br>&nbsp;name: deployment-example<br>spec:<br>&nbsp;replicas: 5<br>&nbsp;selector:<br>&nbsp; matchLabels:<br>&nbsp;&nbsp; app: prodv1<br>&nbsp;template:<br>&nbsp; metadata:<br>&nbsp;&nbsp; labels:<br>&nbsp;&nbsp;&nbsp; app: prodv1<br>&nbsp; spec:<br>&nbsp;&nbsp; containers:<br>&nbsp;&nbsp; - name: web<br>&nbsp;&nbsp;&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;production:v1<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>clusteripdep.yaml<br>apiVersion: v1<br>kind: Service<br>metadata:<br>&nbsp;name: clusterdep<br>spec:<br>&nbsp;type: ClusterIP<br>&nbsp;ports:<br>&nbsp;- targetPort: 80<br>&nbsp;&nbsp; port: 5000<br>&nbsp;selector:&nbsp;<br>&nbsp; app: prodv1<br>&nbsp;&nbsp;<br>[root@master scripts]# kubectl set image deployment&#x2F;deployment-example web=quay.io&#x2F;gauravkumar9130&#x2F;production:v2 --record<br>Flag --record has been deprecated, --record will be removed in the future<br>deployment.apps&#x2F;deployment-example image updated<br>[root@master scripts]# kubectl set image deployment&#x2F;deployment-example web=quay.io&#x2F;gauravkumar9130&#x2F;production:v3 --record<br>Flag --record has been deprecated, --record will be removed in the future<br>deployment.apps&#x2F;deployment-example image updated<br>[root@master scripts]# kubectl rollout history deployment&#x2F;deployment-example<br>deployment.apps&#x2F;deployment-example&nbsp;<br>REVISION&nbsp; CHANGE-CAUSE<br>1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;<br>2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kubectl set image deployment&#x2F;deployment-example web=quay.io&#x2F;gauravkumar9130&#x2F;production:v2 --record=true<br>3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kubectl set image deployment&#x2F;deployment-example web=quay.io&#x2F;gauravkumar9130&#x2F;production:v3 --record=true<br><br>[root@master scripts]# kubectl rollout undo deployment&#x2F;deployment-example<br>deployment.apps&#x2F;deployment-example rolled back<br>[root@master scripts]# kubectl rollout history deployment&#x2F;deployment-example<br>deployment.apps&#x2F;deployment-example&nbsp;<br>REVISION&nbsp; CHANGE-CAUSE<br>1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;<br>2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kubectl set image deployment&#x2F;deployment-example web=quay.io&#x2F;gauravkumar9130&#x2F;production:v2 --record=true<br>5&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kubectl set image deployment&#x2F;deployment-example web=quay.io&#x2F;gauravkumar9130&#x2F;production:v3 --record=true<br>6&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; kubectl set image deployment&#x2F;deployment-example web=quay.io&#x2F;gauravkumar9130&#x2F;production:v4 --record=true<br>-----------------------------<br><strong>Exercise</strong><br>Create a pod with image quay.io&#x2F;gauravkumar9130&#x2F;production:v2 as follows<br><ol start="1" class="number"><li>The pod should be scheduled on node 2 only.&nbsp;</li><li>Node 2 should have label before it accepts pod</ol><br>Create a deployment with image quay.io&#x2F;gauravkumar9130&#x2F;production:v1 as follows<br><ol start="1" class="number"><li>There must be atleast 4 replicas of pod at anytime</li><li>&nbsp;Administrator should be able to upgrade from v1 to v2 easily via command line</ol><br><br><br>-------------------<br><strong>Day 9</strong><br><strong>blue-green deployment</strong><br>blue.yaml<br>apiVersion: apps&#x2F;v1<br>kind: Deployment<br>metadata:<br>&nbsp;name: blue-version<br>spec:<br>&nbsp;replicas: 5<br>&nbsp;selector:<br>&nbsp; matchLabels:<br>&nbsp;&nbsp; version: blue<br>&nbsp;template:<br>&nbsp; metadata:<br>&nbsp;&nbsp; labels:<br>&nbsp;&nbsp;&nbsp; version: blue<br>&nbsp; spec:<br>&nbsp;&nbsp; containers:<br>&nbsp;&nbsp; - name: blue-container<br>&nbsp;&nbsp;&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;production:v1<br><br>blue-green-service.yaml<br>apiVersion: v1<br>kind: Service<br>metadata:<br>&nbsp;name: bluegreenservice<br>spec:<br>&nbsp;type: ClusterIP<br>&nbsp;ports:<br>&nbsp;- targetPort: 80 #port of container<br>&nbsp;&nbsp; port: 80 #port for accessing with clusterIP<br>&nbsp;selector:<br>&nbsp; version: blue<br>&nbsp;&nbsp;<br>green.yaml<br>apiVersion: apps&#x2F;v1<br>kind: Deployment<br>metadata:<br>&nbsp;name: green-version<br>spec:<br>&nbsp;replicas: 5<br>&nbsp;selector:<br>&nbsp; matchLabels:<br>&nbsp;&nbsp; version: green<br>&nbsp;template:<br>&nbsp; metadata:<br>&nbsp;&nbsp; labels:<br>&nbsp;&nbsp;&nbsp; version: green<br>&nbsp; spec:<br>&nbsp;&nbsp; containers:<br>&nbsp;&nbsp; - name: green-container<br>&nbsp;&nbsp;&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;production:v2<br>greenservice.yaml<br>apiVersion: apps&#x2F;v1<br>kind: Deployment<br>metadata:<br>&nbsp;name: green-version<br>spec:<br>&nbsp;replicas: 5<br>&nbsp;selector:<br>&nbsp; matchLabels:<br>&nbsp;&nbsp; version: green<br>&nbsp;template:<br>&nbsp; metadata:<br>&nbsp;&nbsp; labels:<br>&nbsp;&nbsp;&nbsp; version: green<br>&nbsp; spec:<br>&nbsp;&nbsp; containers:<br>&nbsp;&nbsp; - name: green-container<br>&nbsp;&nbsp;&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;production:v2<br>&nbsp; --------<br><strong>&nbsp; environment variables</strong><br><strong>&nbsp; plainkey.yaml</strong><br>&nbsp; apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: pod-plainkey<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: mysql<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mysql<br>&nbsp;&nbsp; env:<br>&nbsp;&nbsp; - name: MYSQL_USER<br>&nbsp;&nbsp;&nbsp;&nbsp; value: sai<br>&nbsp;&nbsp; - name: MYSQL_PASSWORD<br>&nbsp;&nbsp;&nbsp;&nbsp; value: gokul123<br>&nbsp;&nbsp; - name: MYSQL_ROOT_PASSWORD<br>&nbsp;&nbsp;&nbsp;&nbsp; value: root123<br><br>kubectl exec -it pod-plainkey -- bash<br>root@pod-plainkey:&#x2F;# mysql -usai -p<br>Enter password:&nbsp;<br>Welcome to the MySQL monitor.&nbsp; Commands end with ; or \g.<br>Your MySQL connection id is 15<br>Server version: 8.0.22 MySQL Community Server - GPL<br><br>Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.<br><br>Oracle is a registered trademark of Oracle Corporation and&#x2F;or its<br>affiliates. Other names may be trademarks of their respective<br>owners.<br><br>Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.<br><br>mysql&gt; exit<br>Bye<br>root@pod-plainkey:&#x2F;#<br>----------------------<br>------<br><strong>configmap</strong><br>configmapdata.yaml<br>apiVersion: v1<br>kind: ConfigMap<br>metadata:<br>&nbsp;name: db-credentials<br>data:<br>&nbsp;MYSQL_USER: sai<br>&nbsp;MYSQL_PASSWORD: sai123<br>&nbsp;MYSQL_ROOT_PASSWORD: root123<br><br>pod-configmap.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: pod-configmap<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: mysql<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mysql<br>&nbsp;&nbsp; envFrom:<br>&nbsp;&nbsp; - configMapRef:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; name: db-credentials<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>[root@master scripts]# kubectl exec -it pod-configmap -- bash<br>root@pod-configmap:&#x2F;# mysql -usai -p<br>Enter password:&nbsp;<br>Welcome to the MySQL monitor.&nbsp; Commands end with ; or \g.<br>Your MySQL connection id is 8<br>Server version: 8.0.22 MySQL Community Server - GPL<br><br>Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.<br><br>Oracle is a registered trademark of Oracle Corporation and&#x2F;or its<br>affiliates. Other names may be trademarks of their respective<br>owners.<br><br>Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.<br><br>mysql&gt; exit<br>Bye<br>root@pod-configmap:&#x2F;# exit<br>exit<br><br>-------<br>------<br><strong>secret</strong><br>[root@master scripts]# echo -n &quot;sai&quot; | base64<br>c2Fp<br>[root@master scripts]# echo -n &quot;sai123&quot; | base64<br>c2FpMTIz<br>[root@master scripts]# echo -n &quot;root123&quot; | base64<br>cm9vdDEyMw==<br><br>secretdata.yaml<br>apiVersion: v1<br>kind: Secret<br>metadata:<br>&nbsp;name: db-credentials<br>data:<br>&nbsp;MYSQL_USER: c2Fp<br>&nbsp;MYSQL_PASSWORD: c2FpMTIz<br>&nbsp;MYSQL_ROOT_PASSWORD: cm9vdDEyMw==<br><br>pod-secret.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: pod-secret<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: mysql<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;mysql<br>&nbsp;&nbsp; envFrom:<br>&nbsp;&nbsp; - secretRef:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; name: db-credentials<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>[root@master scripts]# kubectl exec -it pod-secret -- bash<br>root@pod-secret:&#x2F;# mysql -usai -p<br>Enter password:&nbsp;<br>Welcome to the MySQL monitor.&nbsp; Commands end with ; or \g.<br>Your MySQL connection id is 8<br>Server version: 8.0.22 MySQL Community Server - GPL<br><br>Copyright (c) 2000, 2020, Oracle and&#x2F;or its affiliates. All rights reserved.<br><br>Oracle is a registered trademark of Oracle Corporation and&#x2F;or its<br>affiliates. Other names may be trademarks of their respective<br>owners.<br><br>Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.<br><br>mysql&gt; exit<br>Bye<br>root@pod-secret:&#x2F;# exit<br>exit<br>-------------------<br>-------------<br><strong>environment variable as volume</strong><br>env-vol-data.yaml<br>apiVersion: v1<br>kind: ConfigMap<br>metadata:<br>&nbsp;name: app-config<br>data:<br>&nbsp;name: sai<br>&nbsp;password: redhat&nbsp;&nbsp;<br><br>config-vol.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: config-pod<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: config<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo<br>&nbsp;&nbsp; volumeMounts:<br>&nbsp;&nbsp; - name: config-vol<br>&nbsp;&nbsp;&nbsp;&nbsp; mountPath: &#x2F;data<br>&nbsp;volumes:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;- name: config-vol&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp; configMap:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; #secret&nbsp;&nbsp;&nbsp;&nbsp; if you are using secret<br>&nbsp;&nbsp;&nbsp; name: app-config&nbsp; #secretName&nbsp;&nbsp; if you are using secret<br>-------------<br><strong>emptydir</strong><br>emptydir.yaml<br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: pod-emptydir<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: emptydir<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo<br>&nbsp;&nbsp; volumeMounts:<br>&nbsp;&nbsp; - name: temporary<br>&nbsp;&nbsp;&nbsp;&nbsp; mountPath: &#x2F;data<br>&nbsp;volumes:<br>&nbsp;- name: temporary<br>&nbsp;&nbsp; emptyDir: {}<br>--------------<br><strong>PersistentVolume</strong><br>pv.yml<br>apiVersion: v1<br>kind: PersistentVolume<br>metadata:<br>&nbsp;name: pv1<br>spec:<br>&nbsp;storageClassName: host<br>&nbsp;accessModes:<br>&nbsp;#ReadWriteOnce - only one node can do readwrite<br>&nbsp;#ReadWriteMany - multiple nodes can do readwrite<br>&nbsp;#ReadOnlyMany - read only volume<br>&nbsp;- ReadWriteMany<br>&nbsp;capacity:<br>&nbsp; storage: 2Gi<br>&nbsp;hostPath:<br>&nbsp; path: &#x2F;myvoldata<br>&nbsp; ------------------<br><strong>&nbsp; Persistent Volume Claim</strong><br><strong>&nbsp; pvc.yaml</strong><br>&nbsp; apiVersion: v1<br>kind: PersistentVolumeClaim<br>metadata:<br>&nbsp;name: pvc1<br>spec:<br>&nbsp;storageClassName: host<br>&nbsp;accessModes:<br>&nbsp;- ReadWriteMany<br>&nbsp;resources:<br>&nbsp; requests:<br>&nbsp;&nbsp; storage: &quot;1Gi&quot;<br>&nbsp;&nbsp; -------------------<br><strong>&nbsp;&nbsp; pod-pvc.yaml</strong><br>&nbsp;&nbsp; apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: podwithpvc<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo<br>&nbsp;&nbsp; volumeMounts:<br>&nbsp;&nbsp; - name: myvol<br>&nbsp;&nbsp;&nbsp;&nbsp; mountPath: &#x2F;mycontainerdata<br>&nbsp;volumes:<br>&nbsp;- name: myvol<br>&nbsp;&nbsp; persistentVolumeClaim:<br>&nbsp;&nbsp;&nbsp; claimName: pvc1&nbsp;<br><br>[root@master scripts]# kubectl create -f pod-pvc.yml&nbsp;<br>pod&#x2F;podwithpvc created<br>[root@master scripts]# kubectl get pod&#x2F;podwithpvc<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE<br>podwithpvc&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 21s<br>[root@master scripts]# kubectl exec -it podwithpvc -- sh<br>&#x2F; # ls<br>bin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; home&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mnt&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; root&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; srv&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; usr<br>dev&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; lib&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; mycontainerdata&nbsp; run&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sys&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; var<br>etc&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; media&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; proc&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; sbin&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; tmp<br>&#x2F; # cd mycontainerdata&#x2F;<br>&#x2F;mycontainerdata # touch sample1.txt sample2.txt<br>&#x2F;mycontainerdata # ls<br>sample1.txt&nbsp; sample2.txt<br>&#x2F;mycontainerdata # exit<br>----------------<br>kubectl get all -n kube-system<br>kubectl api-resources --namespaced=true<br>kubectl api-resources --namespaced=false<br>kubectl get namespace<br>kubectl get pods -A<br>----------------<br><strong>Day 10</strong><br>ServiceAccount<br>serviceaccount.yaml<br>apiVersion: v1<br>kind: ServiceAccount<br>metadata:<br>&nbsp;name: test-serviceaccount<br>&nbsp;namespace: default&nbsp;&nbsp;<br>&nbsp;<br><strong>&nbsp;pod-sa.yaml</strong><br>&nbsp;apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: pod-sa<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo<br>&nbsp;serviceAccountName: test-serviceaccount<br>&nbsp;<br>&nbsp;[root@master ~]# kubectl describe pod&#x2F;pod-sa | grep -i &#x27;service&#x27;<br>Service Account:&nbsp; test-serviceaccount<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &#x2F;var&#x2F;run&#x2F;secrets&#x2F;kubernetes.io&#x2F;serviceaccount from kube-api-access-gptj8 (ro)<br><br><strong>User creation</strong><br>[root@master ~]# git clone <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;gauravkumar9130&#x2F;kube&#x2d;user" rel="noreferrer noopener">https:&#x2F;&#x2F;github.com&#x2F;gauravkumar9130&#x2F;kube-user</a><br>Cloning into &#x27;kube-user&#x27;...<br>remote: Enumerating objects: 3, done.<br>remote: Counting objects: 100% (3&#x2F;3), done.<br>remote: Compressing objects: 100% (2&#x2F;2), done.<br>remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0<br>Unpacking objects: 100% (3&#x2F;3), done.<br>[root@master ~]# ls<br>anaconda-ks.cfg&nbsp; calico.yaml&nbsp; Dockerfile&nbsp; Downloads&nbsp;&nbsp; initial-setup-ks.cfg&nbsp; Music&nbsp;&nbsp;&nbsp;&nbsp; Public&nbsp;&nbsp; service.sh&nbsp; testing<br>binddir&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Desktop&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Documents&nbsp;&nbsp; index.html&nbsp; kube-user&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Pictures&nbsp; scripts&nbsp; Templates&nbsp;&nbsp; Videos<br>[root@master ~]# cd kube-user&#x2F;<br>[root@master kube-user]# ls<br>user_script.sh<br><br>[root@master kube-user]# chmod 700 user_script.sh&nbsp;<br><br><br>[root@master kube-user]# .&#x2F;user_script.sh&nbsp;<br>please type namespace<br>test-ns<br>namespace&#x2F;test-ns created<br>please type username<br>testuser<br>please type testuser password<br>testuser<br>Changing password for user testuser.<br>passwd: all authentication tokens updated successfully.<br>------------------------------Generating Certificates----------------------------------------------<br>Generating RSA private key, 2048 bit long modulus<br>..............+++<br>....................+++<br>e is 65537 (0x10001)<br>&#8216;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.crt&#8217; -&gt; &#8216;&#x2F;root&#x2F;kube-user&#x2F;ca.crt&#8217;<br>&#8216;&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;ca.key&#8217; -&gt; &#8216;&#x2F;root&#x2F;kube-user&#x2F;ca.key&#8217;<br>Signature ok<br>subject=&#x2F;CN=testuser&#x2F;O=test-ns<br>Getting CA Private Key<br>---------------------------------Creating kubeconfig File--------------------------------<br>Cluster &quot;kubernetes&quot; set.<br>------------------------------------ Add user in Kube Config File-----------------------------------<br>User &quot;testuser&quot; set.<br>Context &quot;testuser-kubernetes&quot; created.<br>-------------------- Copying Files --------------------------<br>&#8216;&#x2F;root&#x2F;kube-user&#x2F;ca.crt&#8217; -&gt; &#8216;&#x2F;home&#x2F;testuser&#x2F;.kube&#x2F;ca.crt&#8217;<br>&#8216;&#x2F;root&#x2F;kube-user&#x2F;ca.key&#8217; -&gt; &#8216;&#x2F;home&#x2F;testuser&#x2F;.kube&#x2F;ca.key&#8217;<br>&#8216;&#x2F;root&#x2F;kube-user&#x2F;ca.srl&#8217; -&gt; &#8216;&#x2F;home&#x2F;testuser&#x2F;.kube&#x2F;ca.srl&#8217;<br>&#8216;&#x2F;root&#x2F;kube-user&#x2F;config&#8217; -&gt; &#8216;&#x2F;home&#x2F;testuser&#x2F;.kube&#x2F;config&#8217;<br>&#8216;&#x2F;root&#x2F;kube-user&#x2F;testuser.crt&#8217; -&gt; &#8216;&#x2F;home&#x2F;testuser&#x2F;.kube&#x2F;testuser.crt&#8217;<br>&#8216;&#x2F;root&#x2F;kube-user&#x2F;testuser.csr&#8217; -&gt; &#8216;&#x2F;home&#x2F;testuser&#x2F;.kube&#x2F;testuser.csr&#8217;<br>&#8216;&#x2F;root&#x2F;kube-user&#x2F;testuser.key&#8217; -&gt; &#8216;&#x2F;home&#x2F;testuser&#x2F;.kube&#x2F;testuser.key&#8217;<br>&#8216;&#x2F;root&#x2F;kube-user&#x2F;user_script.sh&#8217; -&gt; &#8216;&#x2F;home&#x2F;testuser&#x2F;.kube&#x2F;user_script.sh&#8217;<br><br><strong>Role and rolebinding</strong><br>[root@master scripts]# kubectl create role testuserrole --verb=create,get,list --resource=pods,services -n test-ns<br>role.rbac.authorization.k8s.io&#x2F;testuserrole created<br>&nbsp;<br>[root@master scripts]# kubectl create rolebinding testrolebind --role=testuserrole --user=testuser -n test-ns<br>rolebinding.rbac.authorization.k8s.io&#x2F;testrolebind created<br><br>[root@master scripts]# kubectl create rolebinding pvbinding --rrole=pvrole --serviceaccount=namespace:saname<br><br><strong>verify role and rolebinding permission</strong><br>[testuser@master ~]$ kubectl auth can-i delete deployments<br>yes<br>[testuser@master ~]$ kubectl auth can-i delete statefulset<br>no<br>------<br>rules:<br>- apiGroups:<br>&nbsp; - &quot;&quot;<br>&nbsp; - apps<br>&nbsp; resources:<br>&nbsp; - pods<br>&nbsp; - services<br>&nbsp; - deployments<br>&nbsp; - replicasets<br>&nbsp; verbs:<br>&nbsp; - create<br>&nbsp; - get<br>&nbsp; - list<br>&nbsp; - exec<br>&nbsp; - watch<br>&nbsp; - update<br>&nbsp; - delete<br>-----<br><strong>Clusterrole and clusterrolebinding</strong><br>[root@master scripts]# kubectl create clusterrole pvrole --verb=get,list --resource=persistentvolumes<br>clusterrole.rbac.authorization.k8s.io&#x2F;pvrole created<br><br>[root@master scripts]# kubectl create clusterrolebinding pvbinding --clusterrole=pvrole --user=testuser<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;pvbinding created<br><br>[root@master scripts]# kubectl create clusterrolebinding pvbinding --clusterrole=pvrole --serviceaccount=namespace:saname<br>---------<br><strong>SecurityContext</strong><br><strong>pod-security.yaml</strong><br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: pod-securitycontext<br>spec:&nbsp;<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo<br>&nbsp;&nbsp; securityContext:<br>&nbsp;&nbsp;&nbsp; capabilities:<br>&nbsp;&nbsp;&nbsp;&nbsp; add: [&quot;NET_RAW&quot;]&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>[root@worker1 ~]# crictl inspect b66818dbef9cba54cbd82cfdb3c8860f1055c7d81d94d4b41f0b8c938de9f677 | grep -A 15 capabilities<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;capabilities&quot;: {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;bounding&quot;: [<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_NET_RAW&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_CHOWN&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_DAC_OVERRIDE&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_FSETID&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_FOWNER&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_SETGID&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_SETUID&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_SETPCAP&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_NET_BIND_SERVICE&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_KILL&quot;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ],<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;effective&quot;: [<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_NET_RAW&quot;,<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;CAP_CHOWN&quot;,<br>----------------<br><strong>logging</strong><br>[root@master scripts]# kubectl logs worker1-pod<br>&nbsp;This is a sample web application that displays a colored background.&nbsp;<br>&nbsp;A color can be specified in two ways.&nbsp;<br><br>&nbsp;1. As a command line argument with --color as the argument. Accepts one of red,green,blue,blue2,pink,darkblue&nbsp;<br>&nbsp;2. As an Environment variable APP_COLOR. Accepts one of red,green,blue,blue2,pink,darkblue&nbsp;<br>&nbsp;3. If none of the above then a random color is picked from the above list.&nbsp;<br>&nbsp;Note: Command line argument precedes over environment variable.<br><br><br>No command line argument or environment variable. Picking a Random Color =red<br>&nbsp;* Serving Flask app &quot;app&quot; (lazy loading)<br>&nbsp;* Environment: production<br>&nbsp;&nbsp; WARNING: Do not use the development server in a production environment.<br>&nbsp;&nbsp; Use a production WSGI server instead.<br>&nbsp;* Debug mode: off<br>&nbsp;* Running on <a href="http&#x3a;&#x2F;&#x2F;0&#x2e;0&#x2e;0&#x2e;0&#x3a;80&#x2F;" rel="noreferrer noopener">http:&#x2F;&#x2F;0.0.0.0:80&#x2F;</a> (Press CTRL+C to quit)<br><br>[root@master scripts]# kubectl logs worker1-pod -c c1<br>&nbsp;This is a sample web application that displays a colored background.&nbsp;<br>&nbsp;A color can be specified in two ways.&nbsp;<br><br>&nbsp;1. As a command line argument with --color as the argument. Accepts one of red,green,blue,blue2,pink,darkblue&nbsp;<br>&nbsp;2. As an Environment variable APP_COLOR. Accepts one of red,green,blue,blue2,pink,darkblue&nbsp;<br>&nbsp;3. If none of the above then a random color is picked from the above list.&nbsp;<br>&nbsp;Note: Command line argument precedes over environment variable.<br><br><br>No command line argument or environment variable. Picking a Random Color =red<br>&nbsp;* Serving Flask app &quot;app&quot; (lazy loading)<br>&nbsp;* Environment: production<br>&nbsp;&nbsp; WARNING: Do not use the development server in a production environment.<br>&nbsp;&nbsp; Use a production WSGI server instead.<br>&nbsp;* Debug mode: off<br>&nbsp;* Running on <a href="http&#x3a;&#x2F;&#x2F;0&#x2e;0&#x2e;0&#x2e;0&#x3a;80&#x2F;" rel="noreferrer noopener">http:&#x2F;&#x2F;0.0.0.0:80&#x2F;</a> (Press CTRL+C to quit)<br><br>-----<br>[root@master ~]# git clone <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;gauravkumar9130&#x2F;grafana" rel="noreferrer noopener">https:&#x2F;&#x2F;github.com&#x2F;gauravkumar9130&#x2F;grafana</a><br>Cloning into &#x27;grafana&#x27;...<br>remote: Enumerating objects: 21, done.<br>remote: Total 21 (delta 0), reused 0 (delta 0), pack-reused 21<br>Unpacking objects: 100% (21&#x2F;21), done.<br>[root@master ~]# cd grafana&#x2F;<br>[root@master grafana]# ls<br>1-prometheus&nbsp; 2-grafana<br><br>[root@master grafana]# kubectl create -f 1-prometheus&#x2F;.<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;kube-state-metrics created<br>clusterrole.rbac.authorization.k8s.io&#x2F;kube-state-metrics created<br>deployment.apps&#x2F;kube-state-metrics created<br>namespace&#x2F;monitoring created<br>clusterrole.rbac.authorization.k8s.io&#x2F;prometheus created<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;prometheus created<br>configmap&#x2F;prometheus-server-conf created<br>deployment.apps&#x2F;prometheus-deployment created<br>service&#x2F;prometheus-service created<br>serviceaccount&#x2F;kube-state-metrics created<br>service&#x2F;kube-state-metrics created<br><br>[root@master grafana]# kubectl get all -n monitoring<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE<br>pod&#x2F;prometheus-deployment-588ff6c558-r2gmc&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3m41s<br><br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; TYPE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CLUSTER-IP&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; EXTERNAL-IP&nbsp;&nbsp; PORT(S)&nbsp;&nbsp;&nbsp; AGE<br>service&#x2F;prometheus-service&nbsp;&nbsp; ClusterIP&nbsp;&nbsp; 10.101.139.90&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8080&#x2F;TCP&nbsp;&nbsp; 3m41s<br><br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; UP-TO-DATE&nbsp;&nbsp; AVAILABLE&nbsp;&nbsp; AGE<br>deployment.apps&#x2F;prometheus-deployment&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3m41s<br><br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; DESIRED&nbsp;&nbsp; CURRENT&nbsp;&nbsp; READY&nbsp;&nbsp; AGE<br>replicaset.apps&#x2F;prometheus-deployment-588ff6c558&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3m41s<br>-------------------<br><strong>grafana</strong><br>[root@master grafana]# kubectl create -f 2-grafana&#x2F;.<br>deployment.apps&#x2F;grafana created<br>configmap&#x2F;grafana-datasources created<br>service&#x2F;grafana created<br><br><strong>If grafana doesn&#x27;t load</strong><br><strong>yum update firefox on both worker nodes</strong><br><br>[root@master grafana]# kubectl delete -f 2-grafana&#x2F;.<br>deployment.apps &quot;grafana&quot; deleted<br>configmap &quot;grafana-datasources&quot; deleted<br>service &quot;grafana&quot; deleted<br>[root@master grafana]# kubectl create -f 2-grafana&#x2F;.<br>deployment.apps&#x2F;grafana created<br>configmap&#x2F;grafana-datasources created<br>service&#x2F;grafana created<br><br><strong>if prometheus doesn&#x27;t load</strong><br>kubectl rollout restart deployment prometheus-deployment -n monitoring<br><br>kubectl delete -f 1-prometheus&#x2F;.<br>kubectl create -f 1-prometheus&#x2F;.<br><br><strong>metric server</strong><br>[root@master grafana]# cd<br>[root@master ~]#&nbsp;<br>[root@master ~]# git clone <a href="https&#x3a;&#x2F;&#x2F;github&#x2e;com&#x2F;gauravkumar9130&#x2F;metrics&#x2d;server&#x2e;git" rel="noreferrer noopener">https:&#x2F;&#x2F;github.com&#x2F;gauravkumar9130&#x2F;metrics-server.git</a><br>Cloning into &#x27;metrics-server&#x27;...<br>remote: Enumerating objects: 14, done.<br>remote: Counting objects: 100% (14&#x2F;14), done.<br>remote: Compressing objects: 100% (12&#x2F;12), done.<br>remote: Total 14 (delta 5), reused 10 (delta 1), pack-reused 0<br>Unpacking objects: 100% (14&#x2F;14), done.<br>[root@master ~]# cd metrics-server&#x2F;<br>[root@master metrics-server]# ls<br>aggregated-metrics-reader.yaml&nbsp; auth-reader.yaml&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; metrics-server-deployment.yaml&nbsp; README.md<br>auth-delegator.yaml&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; metrics-apiservice.yaml&nbsp; metrics-server-service.yaml&nbsp;&nbsp;&nbsp;&nbsp; resource-reader.yaml<br>[root@master metrics-server]# kubectl create -f .<br>clusterrole.rbac.authorization.k8s.io&#x2F;system:aggregated-metrics-reader created<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;metrics-server:system:auth-delegator created<br>rolebinding.rbac.authorization.k8s.io&#x2F;metrics-server-auth-reader created<br>apiservice.apiregistration.k8s.io&#x2F;v1beta1.metrics.k8s.io created<br>serviceaccount&#x2F;metrics-server created<br>deployment.apps&#x2F;metrics-server created<br>service&#x2F;metrics-server created<br>clusterrole.rbac.authorization.k8s.io&#x2F;system:metrics-server created<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;system:metrics-server created<br><br>If metric-server doesn&#x27;t load<br>ctl edit deployment.apps&#x2F;metrics-server kube-n kube-system<br>open metric-server deployment under kube-system namespace and add one line under spec in template<br>kubectl edit deployment.apps&#x2F;metrics-server -n kube-system<br><br>hostNetwork: true<br><br><strong>restart deployment</strong><br>kubectl rollout restart deployment metric-server -n kubesystem<br><br><strong>verification</strong><br>[root@master metrics-server]# kubectl top node<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CPU(cores)&nbsp;&nbsp; CPU%&nbsp;&nbsp; MEMORY(bytes)&nbsp;&nbsp; MEMORY%&nbsp;&nbsp;&nbsp;<br>master&nbsp;&nbsp;&nbsp; 650m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8%&nbsp;&nbsp;&nbsp;&nbsp; 2734Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 17%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>worker1&nbsp;&nbsp; 179m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2%&nbsp;&nbsp;&nbsp;&nbsp; 2775Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 17%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>worker2&nbsp;&nbsp; 233m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2%&nbsp;&nbsp;&nbsp;&nbsp; 4217Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 26%&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>[root@master metrics-server]# kubectl top pod<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CPU(cores)&nbsp;&nbsp; MEMORY(bytes)&nbsp;&nbsp;&nbsp;<br>blue-version-6fcc967f99-2njq2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>blue-version-6fcc967f99-5trht&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>blue-version-6fcc967f99-b4zt9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>blue-version-6fcc967f99-h5bz4&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>blue-version-6fcc967f99-p9tv9&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>config-pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>deployment-example-8665d9bf97-78hcs&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>deployment-example-8665d9bf97-pdh9w&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>deployment-example-8665d9bf97-rl6nv&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>deployment-example-8665d9bf97-vpxk4&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>deployment-example-8665d9bf97-whg5h&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 20Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>green-version-65b6c4c55d-6znbk&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>green-version-65b6c4c55d-chgzb&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>green-version-65b6c4c55d-n2swq&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>nginx-pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>pod-configmap&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 399Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>pod-emptydir&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>pod-plainkey&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 438Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>pod-sa&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>pod-secret&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 395Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>pod-securitycontext&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>podwithlabel&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 20Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>podwithpvc&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rc-example-9l2rl&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rc-example-n27wh&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rc-example-rxxtj&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rs-example-mxh7d&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rs-example-pk6lf&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rs-example-qtbj7&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rs-webapp-bkq4m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rs-webapp-kbl8m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rs-webapp-r2vst&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rs-webapp-xztsm&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>rs-webapp-zqq9v&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>test-pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>worker1-pod&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1m&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 16Mi&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>-----------------------<br><strong>Day 11</strong><br><strong>networking</strong><br>[root@master scripts]# kubectl run web --image=quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo -l app=web<br>pod&#x2F;web created<br>[root@master scripts]# kubectl run db --image=quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo -l app=db<br>pod&#x2F;db created<br>[root@master scripts]# kubectl run test --image=quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo -l app=test<br>pod&#x2F;test created<br>----------<br>mkdir -p $HOME&#x2F;.kube<br>sudo cp -i &#x2F;etc&#x2F;kubernetes&#x2F;admin.conf $HOME&#x2F;.kube&#x2F;config<br>sudo chown $(id -u):$(id -g) $HOME&#x2F;.kube&#x2F;config<br>-----------<br><strong>np-denyall.yaml</strong><br>apiVersion: networking.k8s.io&#x2F;v1<br>kind: NetworkPolicy<br>metadata:<br>&nbsp;name: denypolicy<br>spec:<br>&nbsp;#2 actions<br>&nbsp;#first action -&gt; select the pods by matching labels<br>&nbsp;#second action -&gt; apply the rules on selected pods<br>&nbsp;podSelector:<br>&nbsp; matchLabels:<br>&nbsp;&nbsp; app: db<br>&nbsp;policyTypes:<br>&nbsp;- Ingress&nbsp;&nbsp;<br>&nbsp;-------<br><strong>&nbsp;np-db.yaml</strong><br>&nbsp;apiVersion: networking.k8s.io&#x2F;v1<br>kind: NetworkPolicy<br>metadata:<br>&nbsp;name: dbpolicy<br>spec:&nbsp;&nbsp;&nbsp;<br>&nbsp;#2 actions<br>&nbsp;#first action -&gt; select the pods by matching labels<br>&nbsp;#second action -&gt; apply the rules on selected pods<br>&nbsp;podSelector:<br>&nbsp; matchLabels:<br>&nbsp;&nbsp; app: db<br>&nbsp;policyTypes:<br>&nbsp;- Ingress<br>&nbsp;ingress:<br>&nbsp;- from:<br>&nbsp;&nbsp; - podSelector:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; matchLabels:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; app: web&nbsp;&nbsp;<br>-------<br><strong>np-port-db.yaml</strong><br>apiVersion: networking.k8s.io&#x2F;v1<br>kind: NetworkPolicy<br>metadata:<br>&nbsp;name: portdbpolicy<br>spec:&nbsp;<br>&nbsp;#2 actions<br>&nbsp;#first action -&gt; select the pods by matching labels<br>&nbsp;#second action -&gt; apply the rules on selected pods<br>&nbsp;podSelector:<br>&nbsp; matchLabels:<br>&nbsp;&nbsp; app: db<br>&nbsp;policyTypes:<br>&nbsp;- Ingress<br>&nbsp;ingress:<br>&nbsp;- from:<br>&nbsp;&nbsp; - podSelector:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; matchLabels:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; app: web<br>&nbsp;&nbsp; ports:<br>&nbsp;&nbsp; - protocol: TCP<br>&nbsp;&nbsp;&nbsp;&nbsp; port: 3306&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp; ----<br>&nbsp;&nbsp;&nbsp;&nbsp; [root@master ~]# wget <a href="https&#x3a;&#x2F;&#x2F;raw&#x2e;githubusercontent&#x2e;com&#x2F;metallb&#x2F;metallb&#x2F;v0&#x2e;9&#x2e;5&#x2F;manifests&#x2F;namespace&#x2e;yaml" rel="noreferrer noopener">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;metallb&#x2F;metallb&#x2F;v0.9.5&#x2F;manifests&#x2F;namespace.yaml</a><br>--2022-11-22 16:49:42--&nbsp; <a href="https&#x3a;&#x2F;&#x2F;raw&#x2e;githubusercontent&#x2e;com&#x2F;metallb&#x2F;metallb&#x2F;v0&#x2e;9&#x2e;5&#x2F;manifests&#x2F;namespace&#x2e;yaml" rel="noreferrer noopener">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;metallb&#x2F;metallb&#x2F;v0.9.5&#x2F;manifests&#x2F;namespace.yaml</a><br>Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...<br>Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.<br>HTTP request sent, awaiting response... 200 OK<br>Length: 91 [text&#x2F;plain]<br>Saving to: &#8216;namespace.yaml&#8217;<br><br>100%[================================================================================================&gt;] 91&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; --.-K&#x2F;s&nbsp;&nbsp; in 0s&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br><br>2022-11-22 16:49:43 (4.83 MB&#x2F;s) - &#8216;namespace.yaml&#8217; saved [91&#x2F;91]<br><br>[root@master ~]# wget <a href="https&#x3a;&#x2F;&#x2F;raw&#x2e;githubusercontent&#x2e;com&#x2F;metallb&#x2F;metallb&#x2F;v0&#x2e;9&#x2e;5&#x2F;manifests&#x2F;metallb&#x2e;yaml" rel="noreferrer noopener">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;metallb&#x2F;metallb&#x2F;v0.9.5&#x2F;manifests&#x2F;metallb.yaml</a><br>--2022-11-22 16:51:08--&nbsp; <a href="https&#x3a;&#x2F;&#x2F;raw&#x2e;githubusercontent&#x2e;com&#x2F;metallb&#x2F;metallb&#x2F;v0&#x2e;9&#x2e;5&#x2F;manifests&#x2F;metallb&#x2e;yaml" rel="noreferrer noopener">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;metallb&#x2F;metallb&#x2F;v0.9.5&#x2F;manifests&#x2F;metallb.yaml</a><br>Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...<br>Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.<br>HTTP request sent, awaiting response... 200 OK<br>Length: 7517 (7.3K) [text&#x2F;plain]<br>Saving to: &#8216;metallb.yaml&#8217;<br><br>100%[================================================================================================&gt;] 7,517&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; --.-K&#x2F;s&nbsp;&nbsp; in 0s&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br><br>2022-11-22 16:51:09 (59.9 MB&#x2F;s) - &#8216;metallb.yaml&#8217; saved [7517&#x2F;7517]<br><br>[root@master ~]# kubectl apply -f namespace.yaml&nbsp;<br>namespace&#x2F;metallb-system created<br>[root@master ~]# kubectl apply -f metallb.yaml&nbsp;<br>serviceaccount&#x2F;controller created<br>serviceaccount&#x2F;speaker created<br>clusterrole.rbac.authorization.k8s.io&#x2F;metallb-system:controller created<br>clusterrole.rbac.authorization.k8s.io&#x2F;metallb-system:speaker created<br>role.rbac.authorization.k8s.io&#x2F;config-watcher created<br>role.rbac.authorization.k8s.io&#x2F;pod-lister created<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;metallb-system:controller created<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;metallb-system:speaker created<br>rolebinding.rbac.authorization.k8s.io&#x2F;config-watcher created<br>rolebinding.rbac.authorization.k8s.io&#x2F;pod-lister created<br>daemonset.apps&#x2F;speaker created<br>deployment.apps&#x2F;controller created<br>resource mapping not found for name: &quot;controller&quot; namespace: &quot;metallb-system&quot; from &quot;metallb.yaml&quot;: no matches for kind &quot;PodSecurityPolicy&quot; in version &quot;policy&#x2F;v1beta1&quot;<br>ensure CRDs are installed first<br>resource mapping not found for name: &quot;speaker&quot; namespace: &quot;metallb-system&quot; from &quot;metallb.yaml&quot;: no matches for kind &quot;PodSecurityPolicy&quot; in version &quot;policy&#x2F;v1beta1&quot;<br>ensure CRDs are installed first<br><br><strong>create secret</strong><br>[root@master ~]# kubectl create secret generic -n metallb-system memberlist --from-literal=secrekey=&quot;$(openssl rand -base64 128)&quot;<br>secret&#x2F;memberlist created&nbsp;<br><br>[root@master ~]# kubectl delete secret memberlist -n metallb-system&nbsp;<br>secret &quot;memberlist&quot; deleted<br>[root@master ~]# kubectl create secret generic -n metallb-system memberlist --from-literal=secretkey=&quot;$(openssl rand -base64 128)&quot;<br>secret&#x2F;memberlist created<br><br><strong>configmap.yaml</strong><br>apiVersion: v1<br>kind: ConfigMap<br>metadata:<br>&nbsp;name: config<br>&nbsp;namespace: metallb-system<br>data:<br>&nbsp;config: |<br>&nbsp; address-pools:<br>&nbsp; - name: default<br>&nbsp;&nbsp;&nbsp; protocol: layer2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp; addresses:<br>&nbsp;&nbsp;&nbsp; - 172.25.230.20-172.25.230.30<br><strong>pod-dns.yaml</strong><br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: pod-dns<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: test<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo<br>&nbsp;dnsPolicy: &quot;None&quot; #dns setttings are not inherited<br>&nbsp;dnsConfig:<br>&nbsp; nameservers:<br>&nbsp; - 172.25.250.254<br>&nbsp; searches:<br>&nbsp; - koenig-cloud.com<br>&nbsp; options:<br>&nbsp; - name: ndots<br>&nbsp;&nbsp;&nbsp; value: &quot;5&quot;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp; - name: edns0<br><br>[root@master ~]# kubectl exec -it pod-dns -- sh<br>&#x2F; # cat &#x2F;etc&#x2F;resolv.conf&nbsp;<br>search koenig-cloud.com<br>nameserver 172.25.250.254<br>options ndots:5 edns0<br>&#x2F; # exit<br>--------------------------<br><strong>Ingress</strong><br>[root@master ~]# wget <a href="https&#x3a;&#x2F;&#x2F;raw&#x2e;githubusercontent&#x2e;com&#x2F;kubernetes&#x2F;ingress&#x2d;nginx&#x2F;controller&#x2d;v1&#x2e;1&#x2e;1&#x2F;deploy&#x2F;static&#x2F;provider&#x2F;baremetal&#x2F;deploy&#x2e;yaml" rel="noreferrer noopener">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;kubernetes&#x2F;ingress-nginx&#x2F;controller-v1.1.1&#x2F;deploy&#x2F;static&#x2F;provider&#x2F;baremetal&#x2F;deploy.yaml</a><br>--2022-11-22 18:24:24--&nbsp; <a href="https&#x3a;&#x2F;&#x2F;raw&#x2e;githubusercontent&#x2e;com&#x2F;kubernetes&#x2F;ingress&#x2d;nginx&#x2F;controller&#x2d;v1&#x2e;1&#x2e;1&#x2F;deploy&#x2F;static&#x2F;provider&#x2F;baremetal&#x2F;deploy&#x2e;yaml" rel="noreferrer noopener">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;kubernetes&#x2F;ingress-nginx&#x2F;controller-v1.1.1&#x2F;deploy&#x2F;static&#x2F;provider&#x2F;baremetal&#x2F;deploy.yaml</a><br>Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...<br>Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.<br>HTTP request sent, awaiting response... 200 OK<br>Length: 19190 (19K) [text&#x2F;plain]<br>Saving to: &#8216;deploy.yaml&#8217;<br><br>100%[================================================================================================&gt;] 19,190&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; --.-K&#x2F;s&nbsp;&nbsp; in 0.006s&nbsp;&nbsp;<br><br>2022-11-22 18:24:25 (3.26 MB&#x2F;s) - &#8216;deploy.yaml&#8217; saved [19190&#x2F;19190]<br><br>[root@master ~]# kubectl apply -f deploy.yaml&nbsp;<br>namespace&#x2F;ingress-nginx created<br>serviceaccount&#x2F;ingress-nginx created<br>configmap&#x2F;ingress-nginx-controller created<br>clusterrole.rbac.authorization.k8s.io&#x2F;ingress-nginx created<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;ingress-nginx created<br>role.rbac.authorization.k8s.io&#x2F;ingress-nginx created<br>rolebinding.rbac.authorization.k8s.io&#x2F;ingress-nginx created<br>service&#x2F;ingress-nginx-controller-admission created<br>service&#x2F;ingress-nginx-controller created<br>deployment.apps&#x2F;ingress-nginx-controller created<br>ingressclass.networking.k8s.io&#x2F;nginx created<br>validatingwebhookconfiguration.admissionregistration.k8s.io&#x2F;ingress-nginx-admission created<br>serviceaccount&#x2F;ingress-nginx-admission created<br>clusterrole.rbac.authorization.k8s.io&#x2F;ingress-nginx-admission created<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;ingress-nginx-admission created<br>role.rbac.authorization.k8s.io&#x2F;ingress-nginx-admission created<br>rolebinding.rbac.authorization.k8s.io&#x2F;ingress-nginx-admission created<br>job.batch&#x2F;ingress-nginx-admission-create created<br>job.batch&#x2F;ingress-nginx-admission-patch created<br><br>[root@master ~]# kubectl delete -A ValidatingWebhookConfiguration ingress-nginx-admission<br>validatingwebhookconfiguration.admissionregistration.k8s.io &quot;ingress-nginx-admission&quot; deleted<br><br>-----------------<br><strong>ingress deployment</strong><br>[root@master scripts]# kubectl create deployment hotel --image=quay.io&#x2F;gauravkumar9130&#x2F;hotel --replicas=3<br>deployment.apps&#x2F;hotel created<br>[root@master scripts]# kubectl create deployment tea --image=quay.io&#x2F;gauravkumar9130&#x2F;tea --replicas=3<br>deployment.apps&#x2F;tea created<br>[root@master scripts]# kubectl create deployment coffee --image=quay.io&#x2F;gauravkumar9130&#x2F;coffee --replicas=3<br>deployment.apps&#x2F;coffee created<br>[root@master scripts]# kubectl expose deployment hotel --target-port=80 --port=80<br>service&#x2F;hotel exposed<br>[root@master scripts]# kubectl expose deployment tea --target-port=80 --port=80<br>service&#x2F;tea exposed<br>[root@master scripts]# kubectl expose deployment coffee --target-port=80 --port=80<br>service&#x2F;coffee exposed<br>-----<br><br><br><strong>nginx-rule.yaml</strong><br>apiVersion: networking.k8s.io&#x2F;v1<br>kind: Ingress<br>metadata:<br>&nbsp;name: hotel-ingress<br>&nbsp;annotations: #similar to label and not used for filtering<br>&nbsp; kubernetes.io&#x2F;ingress.class: nginx<br>spec:<br>&nbsp;rules:<br>&nbsp;- host: &quot;myapp.com&quot;<br>&nbsp;&nbsp; http:<br>&nbsp;&nbsp;&nbsp; paths:<br>&nbsp;&nbsp;&nbsp; - path: &#x2F;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pathType: Prefix<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; backend:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; service:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; name: hotel<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; port:<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; number: 80<br>&nbsp;&nbsp;&nbsp; - path: &#x2F;tea&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pathType: Prefix<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; backend:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; service:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; name: tea<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; port:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; number: 80<br>&nbsp;&nbsp;&nbsp; - path: &#x2F;coffee&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; pathType: Prefix<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; backend:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; service:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; name: coffee&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; port:&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; number: 80&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>------<br>[root@master scripts]# curl myapp.com:32468<br>Welcome to Hotel Application<br>[root@master scripts]#&nbsp;<br>[root@master scripts]# curl myapp.com:32468&#x2F;<br>Welcome to Hotel Application[root@master scripts]# curl myapp.com:32468&#x2F;hotel<br>Welcome to Hotel Application[root@master scripts]# curl myapp.com:32468&#x2F;tea<br>Welcome to Tea Application[root@master scripts]# curl myapp.com:32468&#x2F;coffee<br>Welcome to Coffee Application<br><br>--------<br><strong>HELM installation</strong><br>*curl -fsSL -o get_helm.sh <a href="https&#x3a;&#x2F;&#x2F;raw&#x2e;githubusercontent&#x2e;com&#x2F;helm&#x2F;helm&#x2F;main&#x2F;scripts&#x2F;get&#x2d;helm&#x2d;3" rel="noreferrer noopener">https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;helm&#x2F;helm&#x2F;main&#x2F;scripts&#x2F;get-helm-3</a><br>chmod 700 get_helm.sh<br>.&#x2F;get_helm.sh<br>---------------------------------<br><strong>dashboard installation</strong><br>[root@master ~]# kubectl create clusterrolebinding dashboard-admin -n default --clusterrole=cluster-admin --serviceaccount=default:kubernetes-dashboard<br>clusterrolebinding.rbac.authorization.k8s.io&#x2F;dashboard-admin created<br>[root@master ~]# helm repo add kubernetes-dashboard <a href="https&#x3a;&#x2F;&#x2F;kubernetes&#x2e;github&#x2e;io&#x2F;dashboard&#x2F;" rel="noreferrer noopener">https:&#x2F;&#x2F;kubernetes.github.io&#x2F;dashboard&#x2F;</a><br>&quot;kubernetes-dashboard&quot; has been added to your repositories<br>[root@master ~]# helm install kubernetes-dashboard kubernetes-dashboard&#x2F;kubernetes-dashboard<br>NAME: kubernetes-dashboard<br>LAST DEPLOYED: Tue Nov 22 21:46:59 2022<br>NAMESPACE: default<br>STATUS: deployed<br>REVISION: 1<br>TEST SUITE: None<br>NOTES:<br>*********************************************************************************<br>*** PLEASE BE PATIENT: kubernetes-dashboard may take a few minutes to install ***<br>*********************************************************************************<br><br>Get the Kubernetes Dashboard URL by running:<br>&nbsp; export POD_NAME=$(kubectl get pods -n default -l &quot;app.kubernetes.io&#x2F;name=kubernetes-dashboard,app.kubernetes.io&#x2F;instance=kubernetes-dashboard&quot; -o jsonpath=&quot;{.items[0].metadata.name}&quot;)<br>&nbsp; echo <a href="https&#x3a;&#x2F;&#x2F;127&#x2e;0&#x2e;0&#x2e;1&#x3a;8443&#x2F;" rel="noreferrer noopener">https:&#x2F;&#x2F;127.0.0.1:8443&#x2F;</a><br>&nbsp; kubectl -n default port-forward $POD_NAME 8443:8443<br><br>[root@master ~]# helm delete kubernetes-dashboard<br>release &quot;kubernetes-dashboard&quot; uninstalled<br>-------------------------<br><strong>helm</strong><br>[root@master ~]# mkdir helm<br>[root@master ~]# cd helm<br>[root@master helm]# helm create myapp<br>Creating myapp<br>[root@master helm]# ls<br>myapp<br>[root@master helm]# ls myapp&#x2F;<br>charts&nbsp; Chart.yaml&nbsp; templates&nbsp; values.yaml<br><br><strong>Chart.yaml</strong><br>apiVersion: v2 #required&nbsp;<br>name: myapp #required&nbsp;&nbsp;&nbsp;&nbsp;<br>description: A deployment using helm<br>type: application&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>version: 0.1.0 #required&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>appVersion: &quot;1.0&quot;&nbsp;<br><br>[root@master helm]# cd myapp&#x2F;<br>[root@master myapp]# vim values.yaml&nbsp;<br>[root@master myapp]# cd templates&#x2F;<br>[root@master templates]# vim deployment.yaml&nbsp;<br>[root@master templates]# cd ..<br>[root@master myapp]# cd ..<br>[root@master helm]# ls<br>myapp<br>[root@master helm]# helm template myapp<br>---<br>[root@master helm]# helm lint myapp&#x2F;<br>==&gt; Linting myapp&#x2F;<br>[INFO] Chart.yaml: icon is recommended<br><br>1 chart(s) linted, 0 chart(s) failed<br>-----<br>[root@master helm]# helm install sai myapp<br>NAME: sai<br>LAST DEPLOYED: Wed Nov 23 16:09:23 2022<br>NAMESPACE: default<br>STATUS: deployed<br>REVISION: 1<br>NOTES:<br>1. Get the application URL by running these commands:<br>&nbsp; export POD_NAME=$(kubectl get pods --namespace default -l &quot;app.kubernetes.io&#x2F;name=myapp,app.kubernetes.io&#x2F;instance=sai&quot; -o jsonpath=&quot;{.items[0].metadata.name}&quot;)<br>&nbsp; export CONTAINER_PORT=$(kubectl get pod --namespace default $POD_NAME -o jsonpath=&quot;{.spec.containers[0].ports[0].containerPort}&quot;)<br>&nbsp; echo &quot;Visit <a href="http&#x3a;&#x2F;&#x2F;127&#x2e;0&#x2e;0&#x2e;1&#x3a;8080" rel="noreferrer noopener">http:&#x2F;&#x2F;127.0.0.1:8080</a> to use your application&quot;<br>&nbsp; kubectl --namespace default port-forward $POD_NAME 8080:$CONTAINER_PORT<br>-------<br>[root@master helm]# helm list<br>NAME&nbsp;&nbsp;&nbsp; NAMESPACE&nbsp;&nbsp;&nbsp; REVISION&nbsp;&nbsp;&nbsp; UPDATED&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CHART&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; APP VERSION<br>sai&nbsp;&nbsp;&nbsp;&nbsp; default&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2022-11-23 16:09:23.442843356 +0530 IST&nbsp;&nbsp;&nbsp; deployed&nbsp;&nbsp;&nbsp; myapp-0.1.0&nbsp;&nbsp;&nbsp; 1.0&nbsp;&nbsp;<br><br><strong>upgrading chart</strong><br>[root@master helm]# cd myapp&#x2F;<br>[root@master myapp]# vim values.yaml&nbsp;<br>[root@master myapp]# #changed image version in values.yaml to production:v2<br>[root@master myapp]# cd ..<br>[root@master helm]# vim myapp&#x2F;Chart.yaml&nbsp;<br>[root@master helm]# #changed chart version to 0.1.1<br>[root@master helm]# helm upgrade sai myapp&#x2F;<br>Release &quot;sai&quot; has been upgraded. Happy Helming!<br>NAME: sai<br>LAST DEPLOYED: Wed Nov 23 16:53:55 2022<br>NAMESPACE: default<br>STATUS: deployed<br>REVISION: 2<br>NOTES:<br>1. Get the application URL by running these commands:<br>&nbsp; export POD_NAME=$(kubectl get pods --namespace default -l &quot;app.kubernetes.io&#x2F;name=myapp,app.kubernetes.io&#x2F;instance=sai&quot; -o jsonpath=&quot;{.items[0].metadata.name}&quot;)<br>&nbsp; export CONTAINER_PORT=$(kubectl get pod --namespace default $POD_NAME -o jsonpath=&quot;{.spec.containers[0].ports[0].containerPort}&quot;)<br>&nbsp; echo &quot;Visit <a href="http&#x3a;&#x2F;&#x2F;127&#x2e;0&#x2e;0&#x2e;1&#x3a;8080" rel="noreferrer noopener">http:&#x2F;&#x2F;127.0.0.1:8080</a> to use your application&quot;<br>&nbsp; kubectl --namespace default port-forward $POD_NAME 8080:$CONTAINER_PORT<br>[root@master helm]# helm history sai<br>REVISION&nbsp;&nbsp;&nbsp; UPDATED&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CHART&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; APP VERSION&nbsp;&nbsp;&nbsp; DESCRIPTION&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Wed Nov 23 16:09:23 2022&nbsp;&nbsp;&nbsp; superseded&nbsp;&nbsp;&nbsp; myapp-0.1.0&nbsp;&nbsp;&nbsp; 1.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Install complete<br>2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Wed Nov 23 16:53:55 2022&nbsp;&nbsp;&nbsp; deployed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; myapp-0.1.1&nbsp;&nbsp;&nbsp; 1.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Upgrade complete<br><br><strong>downgrading helm chart&nbsp;</strong><br>[root@master helm]# helm rollback sai 1<br>Rollback was a success! Happy Helming!<br>[root@master helm]# helm history sai<br>REVISION&nbsp;&nbsp;&nbsp; UPDATED&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; CHART&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; APP VERSION&nbsp;&nbsp;&nbsp; DESCRIPTION&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Wed Nov 23 16:09:23 2022&nbsp;&nbsp;&nbsp; superseded&nbsp;&nbsp;&nbsp; myapp-0.1.0&nbsp;&nbsp;&nbsp; 1.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Install complete<br>2&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Wed Nov 23 16:53:55 2022&nbsp;&nbsp;&nbsp; superseded&nbsp;&nbsp;&nbsp; myapp-0.1.1&nbsp;&nbsp;&nbsp; 1.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Upgrade complete<br>3&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Wed Nov 23 17:17:35 2022&nbsp;&nbsp;&nbsp; deployed&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; myapp-0.1.0&nbsp;&nbsp;&nbsp; 1.0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Rollback to 1&nbsp;&nbsp;&nbsp;<br>[root@master helm]# helm status sai<br>NAME: sai<br>LAST DEPLOYED: Wed Nov 23 17:17:35 2022<br>NAMESPACE: default<br>STATUS: deployed<br>REVISION: 3<br>NOTES:<br>1. Get the application URL by running these commands:<br>&nbsp; export POD_NAME=$(kubectl get pods --namespace default -l &quot;app.kubernetes.io&#x2F;name=myapp,app.kubernetes.io&#x2F;instance=sai&quot; -o jsonpath=&quot;{.items[0].metadata.name}&quot;)<br>&nbsp; export CONTAINER_PORT=$(kubectl get pod --namespace default $POD_NAME -o jsonpath=&quot;{.spec.containers[0].ports[0].containerPort}&quot;)<br>&nbsp; echo &quot;Visit <a href="http&#x3a;&#x2F;&#x2F;127&#x2e;0&#x2e;0&#x2e;1&#x3a;8080" rel="noreferrer noopener">http:&#x2F;&#x2F;127.0.0.1:8080</a> to use your application&quot;<br>&nbsp; kubectl --namespace default port-forward $POD_NAME 8080:$CONTAINER_PORT<br><br><strong>Cluster maintenance</strong><br><strong>Upgrade OS</strong><br>[root@master helm]# kubectl drain worker1 --force --ignore-daemonsets --delete-emptydir-data<br>----Upgrade OS------<br>[root@master helm]# kubectl uncordon worker1<br><br><strong>Upgrade cluster</strong><br><strong>upgrade kubelet, kubectl and kubeadm</strong><br>[root@master helm]# kubectl drain worker1 --force --ignore-daemonsets --delete-emptydir-data<br>[root@master helm]# #yum upgrade kubeadm-1.25.x kubectl-1.25.x kubelet-1.25.x -y<br>[root@master helm]# #systemctl daemon-reload<br>[root@master helm]# #systemctl restart kubelet<br>[root@master helm]# #kubectl uncordon worker1<br>[root@master helm]# kubectl uncordon worker1<br><br><strong>Control plane upgrade</strong><br>[root@master helm]# kubeadm upgrade plan<br>[upgrade&#x2F;config] Making sure the configuration is correct:<br>[upgrade&#x2F;config] Reading configuration from the cluster...<br>[upgrade&#x2F;config] FYI: You can look at this config file with &#x27;kubectl -n kube-system get cm kubeadm-config -o yaml&#x27;<br>[preflight] Running pre-flight checks.<br>[upgrade] Running cluster health checks<br>[upgrade] Fetching available versions to upgrade to<br>[upgrade&#x2F;versions] Cluster version: v1.25.4<br>[upgrade&#x2F;versions] kubeadm version: v1.25.4<br>[upgrade&#x2F;versions] Target version: v1.25.4<br>[upgrade&#x2F;versions] Latest version in the v1.25 series: v1.25.4<br><br>[root@master helm]# kubeadm upgrade apply v1.25.4<br><br>------<br><strong>static pod (preferably worker node &#x2F;etc&#x2F;kubernetes&#x2F;manifests)</strong><br>[root@worker1 ~]# cd &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;<br>[root@worker1 manifests]# ls<br><br><strong>staticpod.yaml</strong><br>apiVersion: v1<br>kind: Pod<br>metadata:<br>&nbsp;name: staticpod<br>spec:<br>&nbsp;containers:<br>&nbsp;- name: c1<br>&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;nginxdemo&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ---------<br><strong>ETCD backup</strong><br><br>kubectl create ns test-ns&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; [root@master ~]# kubectl run sample-pod --image=quay.io&#x2F;gauravkumar9130&#x2F;production:v1 -n test-ns<br>pod&#x2F;sample-pod created<br>[root@master ~]# kubectl get pods -n test-ns<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; READY&nbsp;&nbsp; STATUS&nbsp;&nbsp;&nbsp; RESTARTS&nbsp;&nbsp; AGE<br>sample-pod&nbsp;&nbsp; 1&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp; Running&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9s<br><br><strong>create backup</strong><br>ETCDCTL_API=3 etcdctl --endpoints <a href="https&#x3a;&#x2F;&#x2F;127&#x2e;0&#x2e;0&#x2e;1&#x3a;2379" rel="noreferrer noopener">https:&#x2F;&#x2F;127.0.0.1:2379</a> --cacert=&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;ca.crt --cert=&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.crt --key=&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.key snapshot save etcdbackup.db<br><br><strong>delete some resource</strong><br>[root@master ~]# kubectl delete namespace test-ns<br>namespace &quot;test-ns&quot; deleted<br>^C[root@master ~]# kubectl get ns test-ns -o json &gt; test-ns.json<br>[root@master ~]# vim test-ns.json&nbsp;<br>[root@master ~]# kubectl replace --raw &quot;&#x2F;api&#x2F;v1&#x2F;namespaces&#x2F;test-ns&#x2F;finalize&quot; -f .&#x2F;test-ns.json&nbsp;<br>{&quot;kind&quot;:&quot;Namespace&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;metadata&quot;:{&quot;name&quot;:&quot;test-ns&quot;,&quot;uid&quot;:&quot;81335db8-6328-49a9-b73c-b9f5720b81c7&quot;,&quot;resourceVersion&quot;:&quot;883802&quot;,&quot;creationTimestamp&quot;:&quot;2022-11-21T10:29:21Z&quot;,&quot;deletionTimestamp&quot;:&quot;2022-11-23T15:14:38Z&quot;,&quot;labels&quot;:{&quot;kubernetes.io&#x2F;metadata.name&quot;:&quot;test-ns&quot;},&quot;managedFields&quot;:[{&quot;manager&quot;:&quot;kubectl-create&quot;,&quot;operation&quot;:&quot;Update&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;time&quot;:&quot;2022-11-21T10:29:21Z&quot;,&quot;fieldsType&quot;:&quot;FieldsV1&quot;,&quot;fieldsV1&quot;:{&quot;f:metadata&quot;:{&quot;f:labels&quot;:{&quot;.&quot;:{},&quot;f:kubernetes.io&#x2F;metadata.name&quot;:{}}}}},{&quot;manager&quot;:&quot;kube-controller-manager&quot;,&quot;operation&quot;:&quot;Update&quot;,&quot;apiVersion&quot;:&quot;v1&quot;,&quot;time&quot;:&quot;2022-11-23T15:15:25Z&quot;,&quot;fieldsType&quot;:&quot;FieldsV1&quot;,&quot;fieldsV1&quot;:{&quot;f:status&quot;:{&quot;f:conditions&quot;:{&quot;.&quot;:{},&quot;k:{\&quot;type\&quot;:\&quot;NamespaceContentRemaining\&quot;}&quot;:{&quot;.&quot;:{},&quot;f:lastTransitionTime&quot;:{},&quot;f:message&quot;:{},&quot;f:reason&quot;:{},&quot;f:status&quot;:{},&quot;f:type&quot;:{}},&quot;k:{\&quot;type\&quot;:\&quot;NamespaceDeletionContentFailure\&quot;}&quot;:{&quot;.&quot;:{},&quot;f:lastTransitionTime&quot;:{},&quot;f:message&quot;:{},&quot;f:reason&quot;:{},&quot;f:status&quot;:{},&quot;f:type&quot;:{}},&quot;k:{\&quot;type\&quot;:\&quot;NamespaceDeletionDiscoveryFailure\&quot;}&quot;:{&quot;.&quot;:{},&quot;f:lastTransitionTime&quot;:{},&quot;f:message&quot;:{},&quot;f:reason&quot;:{},&quot;f:status&quot;:{},&quot;f:type&quot;:{}},&quot;k:{\&quot;type\&quot;:\&quot;NamespaceDeletionGroupVersionParsingFailure\&quot;}&quot;:{&quot;.&quot;:{},&quot;f:lastTransitionTime&quot;:{},&quot;f:message&quot;:{},&quot;f:reason&quot;:{},&quot;f:status&quot;:{},&quot;f:type&quot;:{}},&quot;k:{\&quot;type\&quot;:\&quot;NamespaceFinalizersRemaining\&quot;}&quot;:{&quot;.&quot;:{},&quot;f:lastTransitionTime&quot;:{},&quot;f:message&quot;:{},&quot;f:reason&quot;:{},&quot;f:status&quot;:{},&quot;f:type&quot;:{}}}}},&quot;subresource&quot;:&quot;status&quot;}]},&quot;spec&quot;:{},&quot;status&quot;:{&quot;phase&quot;:&quot;Terminating&quot;,&quot;conditions&quot;:[{&quot;type&quot;:&quot;NamespaceDeletionDiscoveryFailure&quot;,&quot;status&quot;:&quot;True&quot;,&quot;lastTransitionTime&quot;:&quot;2022-11-23T15:14:43Z&quot;,&quot;reason&quot;:&quot;DiscoveryFailed&quot;,&quot;message&quot;:&quot;Discovery failed for some groups, 1 failing: unable to retrieve the complete list of server APIs: metrics.k8s.io&#x2F;v1beta1: an error on the server (\&quot;Internal Server Error: \\\&quot;&#x2F;apis&#x2F;metrics.k8s.io&#x2F;v1beta1\\\&quot;: the server could not find the requested resource\&quot;) has prevented the request from succeeding&quot;},{&quot;type&quot;:&quot;NamespaceDeletionGroupVersionParsingFailure&quot;,&quot;status&quot;:&quot;False&quot;,&quot;lastTransit<br>ionTime&quot;:&quot;2022-11-23T15:14:43Z&quot;,&quot;reason&quot;:&quot;ParsedGroupVersions&quot;,&quot;message&quot;:&quot;All legacy kube types successfully parsed&quot;},{&quot;type&quot;:&quot;NamespaceDeletionContentFailure&quot;,&quot;status&quot;:&quot;False&quot;,&quot;lastTransitionTime&quot;:&quot;2022-11-23T15:14:43Z&quot;,&quot;reason&quot;:&quot;ContentDeleted&quot;,&quot;message&quot;:&quot;All content successfully deleted, may be waiting on finalization&quot;},{&quot;type&quot;:&quot;NamespaceContentRemaining&quot;,&quot;status&quot;:&quot;False&quot;,&quot;lastTransitionTime&quot;:&quot;2022-11-23T15:15:25Z&quot;,&quot;reason&quot;:&quot;ContentRemoved&quot;,&quot;message&quot;:&quot;All content successfully removed&quot;},{&quot;type&quot;:&quot;NamespaceFinalizersRemaining&quot;,&quot;status&quot;:&quot;False&quot;,&quot;lastTransitionTime&quot;:&quot;2022-11-23T15:14:43Z&quot;,&quot;reason&quot;:&quot;ContentHasNoFinalizers&quot;,&quot;message&quot;:&quot;All content-preserving finalizers finished&quot;}]}}<br><br><strong>restore etcd</strong><br>[root@master ~]# ETCDCTL_API=3 etcdctl --endpoints <a href="https&#x3a;&#x2F;&#x2F;127&#x2e;0&#x2e;0&#x2e;1&#x3a;2379" rel="noreferrer noopener">https:&#x2F;&#x2F;127.0.0.1:2379</a> --cacert=&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;ca.crt --cert=&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.crt --key=&#x2F;etc&#x2F;kubernetes&#x2F;pki&#x2F;etcd&#x2F;server.key snapshot restore etcdbackup.db<br>2022-11-23 20:57:16.951307 I | mvcc: restore compact to 882267<br>2022-11-23 20:57:16.960866 I | etcdserver&#x2F;membership: added member 8e9e05c52164694d [<a href="http&#x3a;&#x2F;&#x2F;localhost&#x3a;2380" rel="noreferrer noopener">http:&#x2F;&#x2F;localhost:2380</a>] to cluster cdf818194e3a8c32<br><br>[root@master ~]# ls &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;<br>member<br>[root@master ~]# rm -rf &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;member&#x2F;<br>[root@master ~]# ls &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;<br>[root@master ~]# ls &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;<br>member<br>[root@master ~]# rm -rf &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;*<br>[root@master ~]# ls &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;<br><br>[root@master ~]# cd default.etcd&#x2F;<br>[root@master default.etcd]# ls<br>member<br>[root@master default.etcd]# mv member&#x2F; &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;<br>mv: overwrite &#8216;&#x2F;var&#x2F;lib&#x2F;etcd&#x2F;member&#8217;? n<br>[root@master default.etcd]# mv member&#x2F; &#x2F;var&#x2F;lib&#x2F;etcd&#x2F;<br>[root@master default.etcd]#&nbsp;<br>reboot machine<br>------------------------<br><strong>Cronjob</strong><br>[root@master scripts]# cat cronjob.yaml<br>apiVersion: batch&#x2F;v1<br>kind: CronJob<br>metadata:<br>&nbsp;name: cronjob<br>spec:<br>&nbsp;schedule: &quot;*&#x2F;3 * * * *&quot;<br>&nbsp;jobTemplate:<br>&nbsp; spec:<br>&nbsp;&nbsp; template:<br>&nbsp;&nbsp;&nbsp; spec:<br>&nbsp;&nbsp;&nbsp;&nbsp; containers:<br>&nbsp;&nbsp;&nbsp;&nbsp; - name: cronpod<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; image: quay.io&#x2F;gauravkumar9130&#x2F;busybox<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; command: [&quot;&#x2F;bin&#x2F;sh&quot;]<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; args: [&quot;-c&quot;,&quot;date; echo hello from busybox&quot;]<br>&nbsp;&nbsp;&nbsp;&nbsp; restartPolicy: OnFailure<br>[root@master scripts]# kubectl create -f cronjob.yaml&nbsp;<br>cronjob.batch&#x2F;cronjob created<br>[root@master scripts]# kubectl get cronjob<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SCHEDULE&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; SUSPEND&nbsp;&nbsp; ACTIVE&nbsp;&nbsp; LAST SCHEDULE&nbsp;&nbsp; AGE<br>cronjob&nbsp;&nbsp; *&#x2F;3 * * * *&nbsp;&nbsp; False&nbsp;&nbsp;&nbsp;&nbsp; 0&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &lt;none&gt;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 12s<br>[root@master scripts]# kubectl get jobs<br>NAME&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; COMPLETIONS&nbsp;&nbsp; DURATION&nbsp;&nbsp; AGE<br>cronjob-27820344&nbsp;&nbsp; 0&#x2F;1&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0s&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0s<br><br><br><strong>cluster troubleshooting</strong><br><strong>On master node</strong><br>check &#x2F;etc&#x2F;kubernetes&#x2F;manifests&#x2F;<br>kubectl get nodes<br>kubectl describe node&#x2F;nodename<br><br><strong>on worker nodes</strong><br>systemctl status crio<br>systemctl status kubelet<br><br>------------------------<br><strong>ansible</strong><br><br>[root@master ~]# yum install epel-release -y<br>[root@master ~]# yum install ansible -y<br><br>as student user, create the file under ~&#x2F;ansible_scripts<br><strong>inventory</strong><br>worker1<br>worker2<br><br>[worker]<br>worker[1:2]<br><br>[servers]<br>server[a:d]<br><br>#adding groups as members<br>[linux:children]<br>worker<br>servers<br><br>[student@master ansible_scripts]$ ansible all -i inventory --list-hosts<br>&nbsp; hosts (6):<br>&nbsp;&nbsp;&nbsp; worker1<br>&nbsp;&nbsp;&nbsp; worker2<br>&nbsp;&nbsp;&nbsp; servera<br>&nbsp;&nbsp;&nbsp; serverb<br>&nbsp;&nbsp;&nbsp; serverc<br>&nbsp;&nbsp;&nbsp; serverd<br>[student@master ansible_scripts]$ ansible ungrouped -i inventory --list-hosts<br>[WARNING]: No hosts matched, nothing to do<br>&nbsp; hosts (0):<br>[student@master ansible_scripts]$ ansible worker -i inventory --list-hosts<br>&nbsp; hosts (2):<br>&nbsp;&nbsp;&nbsp; worker1<br>&nbsp;&nbsp;&nbsp; worker2<br><br>[student@master ansible_scripts]$ ansible linux -i inventory --list-hosts<br>&nbsp; hosts (6):<br>&nbsp;&nbsp;&nbsp; worker1<br>&nbsp;&nbsp;&nbsp; worker2<br>&nbsp;&nbsp;&nbsp; servera<br>&nbsp;&nbsp;&nbsp; serverb<br>&nbsp;&nbsp;&nbsp; serverc<br>&nbsp;&nbsp;&nbsp; serverd<br><br><strong>ansible.cfg</strong><br>[defaults]<br>inventory = .&#x2F;inventory<br>remote_user = student<br>ask_pass = false<br><br>[privilege_escalation]<br>become = True<br>become_method = sudo<br>become_user = root<br>become_ask_pass = False&nbsp;<br><br>[student@master ansible_scripts]$ ssh-copy-id student@worker1<br>The authenticity of host &#x27;worker1 (172.25.230.24)&#x27; can&#x27;t be established.<br>ECDSA key fingerprint is SHA256:DEl&#x2F;AQO5c6QqytnpqAVzE7xAiVBxgu2azjtQROe4XKM.<br>ECDSA key fingerprint is MD5:40:6e:6b:61:85:b7:60:d7:c8:83:0c:95:13:55:e5:d7.<br>Are you sure you want to continue connecting (yes&#x2F;no)? yes<br>&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed<br>&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys<br>student@worker1&#x27;s password:&nbsp;<br><br>Number of key(s) added: 1<br><br>Now try logging into the machine, with:&nbsp;&nbsp; &quot;sslist modules<br>[root@master ~]# ansible-doc -l<br>[root@master ~]# ansible-doc ping<br><br>[student@master ansible_scripts]$ ssh-keygen<br>Generating public&#x2F;private rsa key pair.<br>Enter file in which to save the key (&#x2F;home&#x2F;student&#x2F;.ssh&#x2F;id_rsa):&nbsp;<br>Enter passphrase (empty for no passphrase):&nbsp;<br>Enter same passphrase again:&nbsp;<br>Your identification has been saved in &#x2F;home&#x2F;student&#x2F;.ssh&#x2F;id_rsa.<br>Your public key has been saved in &#x2F;home&#x2F;student&#x2F;.ssh&#x2F;id_rsa.pub.<br>The key fingerprint is:<br>SHA256:V55FsSqNCbxhxPZLrtcRe0x5b1ooM0bqLG&#x2F;RDwQzFs8 student@master<br>The key&#x27;s randomart image is:<br>+---[RSA 2048]----+<br>|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; .. ..&nbsp; o. |<br>|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; oo =o . . |<br>|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; .=o +E o. |<br>|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; . +o*++o .|<br>|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; So=*== o.|<br>|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; .=.X + +|<br>|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; + + O + |<br>|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; o = . o&nbsp; |<br>|&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; =.&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; |<br>+----[SHA256]-----+<br><br>ssh &#x27;student@worker1&#x27;&quot;<br>and check to make sure that only the key(s) you wanted were added.<br><br>[student@master ansible_scripts]$ ssh-copy-id student@worker2<br>The authenticity of host &#x27;worker2 (172.25.232.187)&#x27; can&#x27;t be established.<br>ECDSA key fingerprint is SHA256:DEl&#x2F;AQO5c6QqytnpqAVzE7xAiVBxgu2azjtQROe4XKM.<br>ECDSA key fingerprint is MD5:40:6e:6b:61:85:b7:60:d7:c8:83:0c:95:13:55:e5:d7.<br>Are you sure you want to continue connecting (yes&#x2F;no)? yes<br>&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: attempting to log in with the new key(s), to filter out any that are already installed<br>&#x2F;usr&#x2F;bin&#x2F;ssh-copy-id: INFO: 1 key(s) remain to be installed -- if you are prompted now it is to install the new keys<br>student@worker2&#x27;s password:&nbsp;<br><br>Number of key(s) added: 1<br><br>Now try logging into the machine, with:&nbsp;&nbsp; &quot;ssh &#x27;student@worker2&#x27;&quot;<br>and check to make sure that only the key(s) you wanted were added.<br><br>-----<br><strong>sudo permission</strong><br>as root user - worker1,worker2<br>visudo<br><br>add the line<br>student ALL=(ALL)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NOPASSWD: ALL<br>-----<br><strong>ping module</strong><br>[student@master ansible_scripts]$ ansible worker -m ping<br>worker2 | SUCCESS =&gt; {<br>&nbsp;&nbsp;&nbsp; &quot;ansible_facts&quot;: {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;<br>&nbsp;&nbsp;&nbsp; },&nbsp;<br>&nbsp;&nbsp;&nbsp; &quot;changed&quot;: false,&nbsp;<br>&nbsp;&nbsp;&nbsp; &quot;ping&quot;: &quot;pong&quot;<br>}<br>worker1 | SUCCESS =&gt; {<br>&nbsp;&nbsp;&nbsp; &quot;ansible_facts&quot;: {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; &quot;discovered_interpreter_python&quot;: &quot;&#x2F;usr&#x2F;bin&#x2F;python&quot;<br>&nbsp;&nbsp;&nbsp; },&nbsp;<br>&nbsp;&nbsp;&nbsp; &quot;changed&quot;: false,&nbsp;<br>&nbsp;&nbsp;&nbsp; &quot;ping&quot;: &quot;pong&quot;<br>}<br><br><strong>shell module</strong><br>[student@master ansible_scripts]$ ansible worker -m shell -a &#x27;hostname;pwd&#x27;<br>worker1 | CHANGED | rc=0 &gt;&gt;<br>worker1<br>&#x2F;home&#x2F;student<br>worker2 | CHANGED | rc=0 &gt;&gt;<br>worker2<br>&#x2F;home&#x2F;student<br><br>[student@master ansible_scripts]$ ansible worker -m shell -a &#x27;yum install git -y&#x27;<br><br>[student@master ansible_scripts]$ ansible worker -m shell -a &#x27;touch &#x2F;home&#x2F;student&#x2F;test1.txt&#x27;<br>[WARNING]: Consider using the file module with state=touch rather than running &#x27;touch&#x27;.&nbsp; If you need to use command because file is<br>insufficient you can add &#x27;warn: false&#x27; to this command task or set &#x27;command_warnings=False&#x27; in ansible.cfg to get rid of this message.<br>worker1 | CHANGED | rc=0 &gt;&gt;<br><br>worker2 | CHANGED | rc=0 &gt;&gt;<br><br>[student@master ansible_scripts]$ ansible worker -m shell -a &#x27;touch &#x2F;root&#x2F;test1.txt&#x27;<br>[WARNING]: Consider using the file module with state=touch rather than running &#x27;touch&#x27;.&nbsp; If you need to use command because file is<br>insufficient you can add &#x27;warn: false&#x27; to this command task or set &#x27;command_warnings=False&#x27; in ansible.cfg to get rid of this message.<br>worker1 | CHANGED | rc=0 &gt;&gt;<br><br>worker2 | CHANGED | rc=0 &gt;&gt;<br><br><strong>copy module</strong><br>[student@master ansible_scripts]$ ansible worker -m copy -a &#x27;content=&quot;Managed by Ansible\n&quot;&nbsp; dest=&#x2F;etc&#x2F;motd&#x27;<br><br>------<br>vim ~&#x2F;.vimrc<br>set cursorline cursorcolumn<br><br><strong>playbook</strong><br><strong>ping.yaml</strong><br>---<br>- name: check ping connectivity on worker nodes<br>&nbsp; hosts: worker<br>&nbsp; tasks:<br>&nbsp; - name: run ping module<br>&nbsp;&nbsp;&nbsp; ping:<br>...<br>[student@master ansible_scripts]$ ansible-playbook ping.yaml<br><br>[student@master ansible_scripts]$ ansible-playbook ping.yaml --syntax-check<br><br>playbook: ping.yaml<br>----------------------<br>[student@master ansible_scripts]$ echo &quot;This is a web page&quot; &gt; index.html<br><br><strong>site.yaml</strong><br>---<br>- name: host a web page<br>&nbsp; hosts: worker<br>&nbsp; tasks:<br>&nbsp; - name: install the latest version of Apache<br>&nbsp;&nbsp;&nbsp; yum:<br>&nbsp;&nbsp;&nbsp;&nbsp; name: httpd<br>&nbsp;&nbsp;&nbsp;&nbsp; state: latest<br>&nbsp; - name: start httpd service<br>&nbsp;&nbsp;&nbsp; service:<br>&nbsp;&nbsp;&nbsp;&nbsp; name: httpd<br>&nbsp;&nbsp;&nbsp;&nbsp; state: started<br>&nbsp;&nbsp;&nbsp;&nbsp; enabled: true<br>&nbsp; - name: copy index.html to &#x2F;var&#x2F;www&#x2F;html&#x2F;<br>&nbsp;&nbsp;&nbsp; copy:<br>&nbsp;&nbsp;&nbsp;&nbsp; src: index.html<br>&nbsp;&nbsp;&nbsp;&nbsp; dest: &#x2F;var&#x2F;www&#x2F;html&#x2F;index.html<br>...<br>[student@master ansible_scripts]$ ansible-playbook site.yaml&nbsp;<br><br>[student@master ansible_scripts]$ curl <a href="http&#x3a;&#x2F;&#x2F;worker1" rel="noreferrer noopener">http:&#x2F;&#x2F;worker1</a><br>This is a web page<br>[student@master ansible_scripts]$ curl <a href="http&#x3a;&#x2F;&#x2F;worker2" rel="noreferrer noopener">http:&#x2F;&#x2F;worker2</a><br>This is a web page<br>--------<br><strong>intranet-site.yaml</strong><br>---<br>- name: host a web page<br>&nbsp; hosts: worker<br>&nbsp; tasks:<br>&nbsp; - name: install the latest version of Apache<br>&nbsp;&nbsp;&nbsp; yum:<br>&nbsp;&nbsp;&nbsp;&nbsp; name: httpd<br>&nbsp;&nbsp;&nbsp;&nbsp; state: latest<br>&nbsp; - name: start httpd service<br>&nbsp;&nbsp;&nbsp; service:<br>&nbsp;&nbsp;&nbsp;&nbsp; name: httpd<br>&nbsp;&nbsp;&nbsp;&nbsp; state: started<br>&nbsp;&nbsp;&nbsp;&nbsp; enabled: true<br>&nbsp; - name: copy index.html to &#x2F;var&#x2F;www&#x2F;html&#x2F;<br>&nbsp;&nbsp;&nbsp; copy:<br>&nbsp;&nbsp;&nbsp;&nbsp; src: index.html<br>&nbsp;&nbsp;&nbsp;&nbsp; dest: &#x2F;var&#x2F;www&#x2F;html&#x2F;index.html<br>- name: verify website from master node<br>&nbsp; hosts: localhost<br>&nbsp; become: no<br>&nbsp; tasks:<br>&nbsp; - name: verify site on worker1<br>&nbsp;&nbsp;&nbsp; uri:<br>&nbsp;&nbsp;&nbsp;&nbsp; url: <a href="http&#x3a;&#x2F;&#x2F;worker1" rel="noreferrer noopener">http:&#x2F;&#x2F;worker1</a><br>&nbsp;&nbsp;&nbsp;&nbsp; return_content: true<br>&nbsp; - name: verify site on worker2<br>&nbsp;&nbsp;&nbsp; uri:<br>&nbsp;&nbsp;&nbsp;&nbsp; url: <a href="http&#x3a;&#x2F;&#x2F;worker2" rel="noreferrer noopener">http:&#x2F;&#x2F;worker2</a><br>&nbsp;&nbsp;&nbsp;&nbsp; return_content: true<br>...<br>[student@master ansible_scripts]$ ansible-playbook intranet-site.yaml -v<br><br><strong>dry run</strong><br>[student@master ansible_scripts]$ ansible-playbook intranet-site.yaml -C<br><br><br><br>
</body>
</html>
